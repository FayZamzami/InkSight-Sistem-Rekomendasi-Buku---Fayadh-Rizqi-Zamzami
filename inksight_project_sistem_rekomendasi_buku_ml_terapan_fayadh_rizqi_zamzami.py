# -*- coding: utf-8 -*-
"""InkSight - Project Sistem Rekomendasi Buku - ML_Terapan - Fayadh Rizqi Zamzami.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PAlrC4aa9Hu1vMA68vm_Rilw2Ya2nIWM

# **Laporan Proyek Akhir Machine Learning Terapan - FAYADH RIZQI ZAMZAMI**

## **Domain Proyek**

Di era digital saat ini, industri buku mengalami transformasi signifikan dengan meningkatnya akses terhadap buku digital dan platform membaca online. Berdasarkan laporan "Global eBook Market Report 2023", pasar buku digital global diproyeksikan mencapai USD 18.7 miliar pada tahun 2023, dengan tingkat pertumbuhan tahunan (CAGR) sebesar 4.9% dari 2023 hingga 2028. Pertumbuhan ini menciptakan tantangan baru dalam hal bagaimana membantu pembaca menemukan buku yang sesuai dengan preferensi mereka di tengah jutaan pilihan yang tersedia.

**Mengapa Masalah Ini Penting untuk Diselesaikan?**

- **Information Overload :** Ledakan konten digital telah menghasilkan lebih dari 4 juta buku yang diterbitkan setiap tahunnya secara global, menciptakan fenomena "paradox of choice" dimana pembaca justru kesulitan menentukan pilihan di tengah banyaknya opsi. Hal ini terbukti dari data yang menunjukkan 67% pembaca mengalami kesulitan menemukan buku berikutnya, dengan 45% dari mereka menghabiskan lebih dari 30 menit hanya untuk mencari buku yang sesuai minat mereka.
- **Damppak Ekonomi :** Ketidakmampuan pembaca dalam menemukan buku yang sesuai telah menciptakan dampak signifikan pada industri perbukuan, dimana 35% potensi pembelian buku gagal terjadi. Namun, platform yang telah mengimplementasikan sistem rekomendasi yang baik melaporkan peningkatan penjualan hingga 50%, dengan retensi pengguna platform membaca online meningkat hingga 40% berkat adanya rekomendasi yang personal.
- **Pengembangan Literasi :** Sistem rekomendasi yang efektif terbukti berperan penting dalam meningkatkan budaya literasi, dimana pembaca yang berhasil menemukan buku sesuai minat memiliki 73% kemungkinan lebih tinggi untuk membaca secara rutin. Hal ini diperkuat dengan data yang menunjukkan bahwa kualitas rekomendasi buku berkorelasi positif dengan peningkatan minat baca, serta personalisasi rekomendasi yang berhasil meningkatkan engagement pembaca hingga 58%.
**Hasil Riset Terkait:**



**Referensi :**
- https://www.researchgate.net/publication/360772285_An_Enhanced_Book_Recommendation_System_Using_Hybrid_Machine_Learning_Techniques

- https://esomar.org/uploads/attachments/clpv6d0qh09v2h53v27nptwra-esomar-global-market-research-2023-chapter-1.pdf

## Business Understanding

### Problem Statements

Berdasarkan kondisi permasalahan yang telah diidentifikasi, berikut adalah beberapa rumusan masalah yang perlu dipecahkan:

- Bagaimana cara mempercepat proses pencarian buku yang sesuai dengan minat dan kebutuhan pembaca?
- Dengan memanfaatkan data penilaian dari pengguna, bagaimana cara mengembangkan sistem yang dapat menyarankan buku-buku yang berpotensi diminati oleh pengguna namun belum pernah mereka baca sebelumnya?

### Goals

Berdasarkan permasalahan yang telah dirumuskan, berikut adalah target pencapaian yang ingin diwujudkan:

- Mengembangkan platform rekomendasi buku yang dapat membantu pengguna dalam menemukan bacaan yang tepat.
- Membangun sistem rekomendasi yang mampu menyesuaikan dengan selera dan preferensi individual pengguna melalui implementasi teknik Collaborative Filtering.

### Solution Statements

Untuk mencapai tujuan yang telah ditetapkan, strategi yang akan diterapkan adalah:

- Mengimplementasikan sistem rekomendasi dengan menggunakan metode Collaborative Filtering sebagai pendekatan utama

## Data Understanding

Dataset yang akan dimanfaatkan dalam penelitian ini adalah Book Recommendation Dataset yang tersedia untuk diunduh melalui tautan berikut: Book Recommendation Dataset. Dataset tersebut terdiri dari tiga file terpisah.

**Users** merupakan kumpulan data yang memuat informasi mengenai pengguna. File ini terdiri dari 278858 baris data dengan 3 kolom utama yaitu User-ID, Location, dan Age.

**Books** merupakan file yang menyimpan detail informasi buku, meliputi ISBN (identifikasi unik buku), nama buku, penulis, tahun penerbitan, nama penerbit, serta URL gambar yang terhubung ke situs web amazon. File ini memuat 271360 baris data dengan 8 kolom. Setiap ISBN merepresentasikan satu buku secara unik. Perlu dicatat bahwa dalam file ini ditemukan beberapa nilai kosong (missing value), khususnya pada kolom book_author, publisher, dan image_url_l.

**Ratings** merupakan file yang menyimpan penilaian yang telah diberikan oleh pengguna terhadap buku-buku tertentu. File ini berisi 1149780 baris data dengan 3 kolom utama yaitu user_id, isbn, dan book_rating.

Secara detail, dataset tersebut memiliki fitur-fitur sebagai berikut:

- **ISBN** berfungsi sebagai penanda unik setiap buku, dimana satu ISBN merujuk pada satu buku
- **book_title** menunjukkan nama/judul buku
- **book_author** menunjukkan nama penulis
- **year_of_publication** menunjukkan tahun publikasi buku
- **publisher** menunjukkan nama penerbit
- **image_url_s** menyimpan URL gambar buku berukuran kecil
- **image_url_m** menyimpan URL gambar buku berukuran medium
- **image_url_l** menyimpan URL gambar buku berukuran besar
- **user_id** berfungsi sebagai identitas unik setiap pengguna
- **location** menunjukkan lokasi geografis pengguna
- **age** menunjukkan usia pengguna
- **rating** menunjukkan nilai penilaian dari pengguna

Untuk memperoleh pemahaman mendalam terhadap karakteristik data, akan dilaksanakan analisis data eksplorasi yang meliputi:

- Menganalisis jenis tipe data pada setiap dataframe
- Memverifikasi bahwa setiap isbn hanya merepresentasikan satu buku
- Mengidentifikasi jumlah data unik pada dataset buku
- Memverifikasi bahwa buku dengan judul sama namun ISBN berbeda merupakan entitas yang terpisah
- Mengidentifikasi jumlah data unik pada dataframe pengguna
- Menganalisis jumlah pengguna yang memberikan penilaian, jumlah buku yang menerima penilaian, dan total data pada dataframe ratings
- Menganalisis kisaran nilai rating yang diberikan pengguna

Berdasarkan analisis yang telah dilakukan, diperoleh hasil sebagai berikut:

- Jenis tipe data yang terdapat dalam dataset adalah int, object, dan float
- Setiap isbn dalam dataframe mengacu pada satu buku secara spesifik
- Dataset memuat 271360 buku unik dengan 242135 judul yang berbeda
- Buku dengan judul identik namun ISBN yang berbeda merupakan buku yang terpisah, mengingat satu judul dapat memiliki beberapa edisi atau seri lanjutan
- Total pengguna dalam dataset berjumlah 278858
- Data rating terdiri dari 1149780 entri, dengan 340556 buku yang telah menerima rating, dan 105283 pengguna yang telah memberikan penilaian
- Skala rating berkisar antara 0 hingga 10

# Import library yang dibutuhkan
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
import seaborn as sns
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

"""# Load Data"""

base_dir = "/content/"
books = pd.read_csv(base_dir+"Books.csv")
ratings = pd.read_csv(base_dir+"Ratings.csv")
users = pd.read_csv(base_dir+"Users.csv")

"""Menyimpan dataset ke dalam variabel

# Exploratory Data Analysis
"""

books

"""Memunculkan dan memperlihatkan sebagian data dari books, dan memperlihatkan seluruh fiturnya

## Mengubah teks pada kolom menjadi huruf kecil sekaligus mengubah "-" menjadi "_" agar mempermudah proses pemanggilan.
"""

books.columns = books.columns.str.lower()
books.columns = books.columns.str.replace("-","_")

ratings.columns = ratings.columns.str.lower()
ratings.columns = ratings.columns.str.replace("-","_")

users.columns = users.columns.str.lower()
users.columns = users.columns.str.replace("-","_")

"""# Penjelasan Kode: Standardisasi Nama Kolom

## **Fungsi Utama**

Kode ini melakukan **standardisasi nama kolom** pada semua dataframe untuk memastikan konsistensi penamaan dan mempermudah akses data.

## **Cara Kerja**

### **1. Konversi ke Huruf Kecil**

```python
books.columns = books.columns.str.lower()
```

**Fungsi:**

- **`.columns`**: Mengakses nama-nama kolom dataframe
- **`.str.lower()`**: Method string yang mengkonversi semua huruf menjadi lowercase
- **Hasil**: `"User-ID"` ‚Üí `"user-id"`

### **2. Penggantian Tanda Hubung**

```python
books.columns = books.columns.str.replace("-","_")
```

**Fungsi:**

- **`.str.replace("-","_")`**: Mengganti semua karakter "-" dengan "_"
- **Parameter**:
- `"-"`: Pattern yang dicari (tanda hubung)
- `"_"`: Replacement string (underscore)
- **Hasil**: `"user-id"` ‚Üí `"user_id"`

## **Parameter yang Digunakan**

| Parameter | Fungsi | Contoh |
| --- | --- | --- |
| **`.str.lower()`** | Konversi ke huruf kecil | `"Book-Title"` ‚Üí `"book-title"` |
| **`.str.replace()`** | Substitusi karakter | `"book-title"` ‚Üí `"book_title"` |
| **Pattern: `"-"`** | Target karakter yang diganti | Tanda hubung |
| **Replacement: `"_"`** | Karakter pengganti | Underscore |

 Kode sederhana ini memastikan **data consistency** yang sangat penting untuk **maintainability** dan **reliability** pipeline data science selanjutnya.
"""

users

"""memunculkan users setelah dilakukan standarisasi

## Melihat jenis tipe data *dataframe books*
"""

books.info()

"""*Data Frame* di atas memiliki 271360 baris data dengan keseluruhannya bertipe data object. Jika dilihat dari keseluruhan total data yang ada, terdapat missing values pada kolom book_author (271359 baris), publisher, dan image_url_l. Namun mari kita tangani nanti.

## Memastikan tiap satu ISBN mencakup satu buku
"""

books["isbn"].duplicated().sum()

"""## judul buku unik"""

print(f"Banyak data buku yang unik berdasarkan judul : {len(books['book_title'].unique())}")
print(f"Banyak data buku yang unik berdasarkan ISBN : {len(books['isbn'].unique())}")

"""Berdasarkan data di atas, didapatkan beberapa informasi sebagai berikut:  
1. Jumlah seluruh data buku yang unik yakni 271360, hal ini karena menunjukkan bahwa satu ISBN hanya untuk satu buku.
2. Terdapat beberapa judul yang sama dengan ISBN yang berbeda, hal ini kemungkinan menunjukkan bahwa data buku dengan judul yang sama merupakan dua entitas yang berbeda. Seperti, kemungkinan buku berjudul x memiliki sequelnya.
"""

books[books["book_title"].duplicated()].sample(5,axis=0)

"""Data di atas merupakan list buku yang memiliki judul yang duplikat. Selanjutnya mari kita lihat salah satu data pada judul buku di atas."""

books[books["book_title"] == "El Ladron De Cuerpos"]

"""Sudah terlihat, bahwa judul buku sama yang memiliki ISBN berbeda merupakan dua entitas yang berbeda. Jika dilihat pada tahun publikasi di atas, buku dengan judul "El Ladron De Cuerpos" dipublikasi pada tahun yang berbeda. Berdasarkan hal tersebut, dapat disimpulkan bahwa buku dengan judul tersebut memiliki sequel lanjutannya.

## Banyak data user yang unik
"""

users

print(f"Banyak data user unik : {len(users['user_id'].unique())}")

users.info()

"""# Penjelasan Kode: Analisis Data User

## **1. Eksplorasi Data User**

```python
users  # Menampilkan dataframe users
```

**Fungsi:** Menampilkan struktur dan sample data dari dataset users

**Output yang terlihat:**

- **278,858 rows √ó 3 columns**: Dataset berisi 278,858 pengguna dengan 3 kolom
- **Kolom**: `user_id`, `location`, `age`
- **Sample data**: Menampilkan beberapa baris pertama dan terakhir

## **2. Menghitung Jumlah User Unik**

```python
print(f"Banyak data user unik : {len(users['user_id'].unique())}")
```

**Cara Kerja:**

- **`users['user_id']`**: Mengakses kolom user_id
- **`.unique()`**: Mengambil nilai-nilai unik (menghilangkan duplikat)
- **`len()`**: Menghitung jumlah elemen
- **f-string**: Format output yang readable

**Output:** `Banyak data user unik : 278858`

**Interpretasi:** Semua user_id adalah unik (tidak ada duplikat)

## **3. Informasi Detail Dataset**

```python
users.info()
```

**Fungsi:** Menampilkan ringkasan teknis dataset

**Output Analysis:**

- **RangeIndex: 278858 entries**: Konfirmasi jumlah baris
- **Data columns (total 3 columns)**:
  - `user_id`: 278858 non-null int64 : Lengkap
  - `location`: 278858 non-null object : Lengkap  
  - `age`: 168096 non-null float64 : Ada missing values

**Missing Values Detection:**

- **Age column**: 278858 - 168096 = **110,762 missing values**
- **Percentage**: (110,762/278,858) √ó 100% = **39.7% data age kosong**

## Banyak data ratings
"""

ratings

"""Memunculkan Data ratisngs,Menampilkan struktur dan sample data dari dataset ratings yang berisi interaksi user-book"""

print(f"Banyak data rating :{len(ratings)}")
print(f"Jumlah buku yang telah diberi rating : {len(ratings['isbn'].unique())}")
print(f"Jumlah user yang memberikan rating : {len(ratings['user_id'].unique())}")

"""Cara Kerja:
- `len(ratings)`: Menghitung total baris/interaksi rating
- `ratings['isbn'].unique()`: Mengambil ISBN unik yang pernah diberi rating
- `ratings['user_id'].unique()`: Mengambil user unik yang pernah memberikan rating

"""

ratings.info()

"""Data Structure:
- 1,149,780 entries: Konfirmasi jumlah total ratings
- 3 columns: user_id, isbn, book_rating

Data Quality:
-  Semua kolom non-null: Tidak ada missing values
- Data lengkap: 100% completeness

Data Types:
- user_id: int64 (ID numerik user)
- isbn: object (string identifier buku)  
- book_rating: int64 (nilai rating numerik)

## Rentang rating
"""

ratings.describe().round(3)

"""Rating buku berentang antara 0 - 10 (terendah ke tertinggi)

# Data Preprocessing
"""

print(f"Jumlah seluruh data buku berdasarkan ISBN : {len(books['isbn'].unique())}")
print(f"Jumlah seluruh data buku berdasarkan judul buku : {len(books['book_title'].unique())}")
print(f"Jumlah seluruh users : {len(users['user_id'].unique())}")
print(f"Jumlah seluruh rating : {len(ratings)}")

"""Memberikan overview statistik dari ketiga dataset sebelum penggabungan

Insight :
- ISBN > Judul: 271,360 - 242,135 = 29,225 buku dengan judul sama tapi ISBN berbeda
- Kemungkinan: Edisi berbeda, penerbit berbeda, atau sequel dari buku yang sama

## Menggabungkan data ratings dengan judul buku
"""

all_book = ratings
all_book

all_book = pd.merge(all_book, books[["isbn","book_title"]], on="isbn", how="left")
all_book

"""**Inisialisasi Dataset Gabungan**

```python
all_book = ratings
all_book
```

**Fungsi:**

- **Membuat salinan** dataset ratings sebagai **base dataset**
- **Starting point** untuk penggabungan dengan informasi buku

**Struktur Awal:**

- **1,149,780 rows √ó 3 columns**: user_id, isbn, book_rating
- **Berisi semua interaksi** user-book yang akan diperkaya dengan metadata buku

**Penggabungan dengan Metadata Buku**

```python
all_book = pd.merge(all_book, books[["isbn","book_title"]], on="isbn", how="left")
all_book
```

**Cara Kerja:**

**Parameter `pd.merge()`:**

- **`all_book`**: Dataset kiri (base) - berisi ratings
- **`books[["isbn","book_title"]]`**: Dataset kanan - hanya kolom ISBN dan judul
- **`on="isbn"`**: Key untuk penggabungan
- **`how="left"`**: Left join - pertahankan semua data dari ratings

**Proses Join:**

```javascript
ratings (1,149,780 rows)  +  books[isbn, title]  ‚Üí  all_book (1,149,780 rows + title)
     ‚Üì                              ‚Üì                        ‚Üì
[user_id, isbn, rating]    [isbn, book_title]    [user_id, isbn, rating, book_title]
```

**Hasil Penggabungan:**

- **1,149,780 rows √ó 4 columns**: Jumlah baris tetap sama
- **Kolom baru**: `book_title` ditambahkan
- **Missing values**: Mungkin ada rating untuk ISBN yang tidak ada di dataset books

Kode ini melakukan **data integration** yang penting untuk memperkaya dataset ratings dengan metadata buku, sehingga hasil akhir lebih informatif dan siap untuk tahap preprocessing selanjutnya.

# Data Preparation

## Menangani *Missing Values*
"""

all_book.isna().sum()

"""Berdasarkan jumlah data rating yang ada (1 juta lebih), *missing value* berjumlah 100 ribu data. Sehingga tidak apa jika kita menghapus *missing value* pada kolom book_title"""

all_book_clean = all_book.dropna()
all_book_clean

"""Setelah menghapus baris data yang mengandung *missing value*, kini data berjumlah 1031136 baris data.

## Membuat dataframe baru yang berisi isbn dan judul buku
"""

preparation = all_book_clean
preparation

"""Membuat alias/salinan dari dataset yang sudah dibersihkan untuk tahap persiapan modeling"""

book_title, isbn = preparation["book_title"].tolist(), preparation["isbn"].tolist()
print(f"Jumlah data judul buku : {len(book_title)}")
print(f"Jumlah data isbn: {len(isbn)}")

"""Cara Kerja:
- `.tolist()`: Mengkonversi pandas Series menjadi Python list
- Multiple assignment: Ekstrak 2 kolom sekaligus dalam 1 baris

Hasil:
- `book_title`: List berisi semua judul buku
- `isbn`: List berisi semua ISBN corresponding

Quality check - memastikan jumlah judul dan ISBN sama
"""

book_new = pd.DataFrame({
    "isbn" : isbn,
    "title" : book_title
})
book_new

"""Membuat lookup table sederhana untuk mapping ISBN ‚Üî Judul buku

## Encode kolom user_id dan isbn
"""

df = ratings
df

isbn_id = df["isbn"].unique().tolist()
user_id = df["user_id"].unique().tolist()

isbn_encoded = {key:values for values, key in enumerate(isbn_id)}
isbn_decoded = {key:values for key, values in enumerate(isbn_id)}

user_encoded = {key:values for values, key in enumerate(user_id)}
user_decoded = {key:values for key, values in enumerate(user_id)}

"""Penjelasan Kode: Encoding User ID dan ISBN

**1. Inisialisasi Dataset**

```python
df = ratings
df
```

**Fungsi:** Membuat **working copy** dari dataset ratings untuk proses encoding

**Output:** Dataset dengan 1,149,780 rows √ó 3 columns (user_id, isbn, book_rating)

**2. Ekstraksi Unique Values**

```python
isbn_id = df["isbn"].unique().tolist()
user_id = df["user_id"].unique().tolist()
```

**Cara Kerja:**

- **`.unique()`**: Mengambil nilai-nilai unik (menghilangkan duplikat)
- **`.tolist()`**: Konversi dari numpy array ke Python list

**Hasil:**

- **`isbn_id`**: List semua ISBN unik dalam dataset
- **`user_id`**: List semua user_id unik dalam dataset

**Contoh:**

```python
isbn_id = ["034545104X", "0155061224", "044652080Z", ...]
user_id = [276725, 276726, 276727, ...]
```

**3. Pembuatan Dictionary Encoding**

**A. ISBN Encoding/Decoding:**

```python
isbn_encoded = {key:values for values, key in enumerate(isbn_id)}
isbn_decoded = {key:values for key, values in enumerate(isbn_id)}
```

**Cara Kerja:**

- **`enumerate(isbn_id)`**: Memberikan index (0,1,2,...) untuk setiap ISBN
- **`isbn_encoded`**: ISBN ‚Üí Integer mapping
- **`isbn_decoded`**: Integer ‚Üí ISBN mapping

**Contoh Output:**

```python
isbn_encoded = {
    "034545104X": 0,
    "0155061224": 1,
    "044652080Z": 2,
    ...
}

isbn_decoded = {
    0: "034545104X",
    1: "0155061224",
    2: "044652080Z",
    ...
}
```

## Mapping terhadap dataframe
"""

df["user_encoded"] = df["user_id"].map(user_encoded)
df["isbn_encoded"] = df["isbn"].map(isbn_encoded)
df

num_users = len(user_encoded)
num_books = len(isbn_encoded)

print(f"Banyak user : {num_users}")
print(f"Banyak buku : {num_books}")

"""Penjelasan Kode: Mapping Encoded Values ke DataFrame

1. Mapping Terhadap DataFrame**

```python
df["user_encoded"] = df["user_id"].map(user_encoded)
df["isbn_encoded"] = df["isbn"].map(isbn_encoded)
df
```

**Fungsi Utama**

Kode ini melakukan **transformasi data kategorik** menjadi **data numerik** yang dapat diproses oleh model machine learning.

**Cara Kerja**

**A. User ID Mapping:**

```python
df["user_encoded"] = df["user_id"].map(user_encoded)
```

**Proses:**

- **`.map(user_encoded)`**: Menggunakan dictionary `user_encoded` untuk mapping
- **Input**: User ID asli (contoh: 276725, 276726, 276727...)
- **Output**: Index numerik berurutan (0, 1, 2, 3...)

**Contoh Transformasi:**

```python
user_encoded = {276725: 0, 276726: 1, 276727: 2, 276729: 3, ...}

# Mapping hasil:
276725 ‚Üí 0
276726 ‚Üí 1  
276727 ‚Üí 2
276729 ‚Üí 3
```

**B. ISBN Mapping:**

```python
df["isbn_encoded"] = df["isbn"].map(isbn_encoded)
```

**Proses:**

- **Input**: ISBN string (contoh: "034545104X", "0155061224"...)
- **Output**: Index numerik berurutan (0, 1, 2, 3...)

**Contoh Transformasi:**

```python
isbn_encoded = {"034545104X": 0, "0155061224": 1, "0446520802": 2, ...}

# Mapping hasil:
"034545104X" ‚Üí 0
"0155061224" ‚Üí 1
"0446520802" ‚Üí 2
```

**Hasil DataFrame**

| user_id | isbn | book_rating | user_encoded | isbn_encoded |
| --- | --- | --- | --- | --- |
| 276725 | 034545104X | 0 | 0 | 0 |
| 276726 | 0155061224 | 5 | 1 | 1 |
| 276727 | 0446520802 | 0 | 2 | 2 |

**2. Menghitung Jumlah Entitas Unik**

```python
num_users = len(user_encoded)
num_books = len(isbn_encoded)

print(f"Banyak user : {num_users}")
print(f"Banyak buku : {num_books}")
```

**Fungsi**

Menghitung **dimensi dataset** yang diperlukan untuk konfigurasi model.

**Cara Kerja**

- **`len(user_encoded)`**: Menghitung jumlah user unik dalam dictionary
- **`len(isbn_encoded)`**: Menghitung jumlah buku unik dalam dictionary

**Output**

```javascript
Banyak user : 105283
Banyak buku : 340556
```



- **Model Architecture**: Menentukan ukuran embedding layer
- **Memory Planning**: Estimasi kebutuhan memori model
- **Sparsity Analysis**: Rasio data vs. kemungkinan kombinasi

Kode ini merupakan **tahap preprocessing krusial** yang memungkinkan data kategorikal (user_id dan ISBN) dapat diproses oleh algoritma machine learning, khususnya untuk implementasi **collaborative filtering** dengan **neural embeddings**.

## Mengubah tipe data kolom book_rating menjadi float
"""

df["book_rating"] = df["book_rating"].values.astype(np.float64)
df

"""Mengkonversi tipe data kolom book_rating dari integer menjadi float64 untuk kompatibilitas dengan model machine learning.



**Cara Kerja**

**1. Ekstraksi Values**

```python
df["book_rating"].values
```

- Mengambil array numpy dari kolom book_rating
- Menghilangkan metadata pandas (index, nama kolom)

**2. Konversi Tipe Data**

```python
.astype(np.float64)
```

- **Input**: Integer array (0, 5, 0, 3, 6, ...)
- **Output**: Float64 array (0.0, 5.0, 0.0, 3.0, 6.0, ...)

**3. Assignment Kembali**

```python
df["book_rating"] = ...
```

- Mengganti kolom asli dengan versi float64

Konversi ini memastikan data rating siap untuk **normalisasi**, **operasi matematika**, dan **input ke model neural network** tanpa masalah kompatibilitas tipe data.

## Membagi data latih dan data validasi

### Mengacak dataframe
"""

df = df.sample(frac=1, random_state=99)
df

"""**Mengacak DataFrame**

```python
df = df.sample(frac=1, random_state=99)
df
```

**Fungsi**

Melakukan **shuffling** pada seluruh dataset untuk memastikan distribusi data yang acak.

**Parameter**

- **`frac=1`**: Mengambil 100% data (semua baris)
- **`random_state=99`**: Seed untuk reproducibility hasil yang sama

**Pentingnya Shuffling**

- **Menghilangkan bias urutan** data asli
- **Memastikan distribusi merata** antara training dan validation
- **Mencegah overfitting** pada pola urutan tertentu

### Membagi data 85% data latih dan 15% data validasi, sekaligus normalisasi kolom rating berkisar 0-1
"""

x = df[["user_encoded","isbn_encoded"]]
min = df["book_rating"].min()
max = df["book_rating"].max()
y = df["book_rating"].apply(lambda x:(x-min) / (max-min) )

split = int(0.85 * df.shape[0])
X_train, X_val, Y_train, Y_val = (
    x[:split],
    x[split:],
    y[:split],
    y[split:]
)

"""Penjelasan Kode: Data Splitting


***

**Persiapan Features dan Target**

```python
x = df[["user_encoded","isbn_encoded"]]
```

**Fungsi**

Membuat **feature matrix** yang berisi input untuk model collaborative filtering.

***

**Normalisasi Rating (Min-Max Scaling)**

```python
min = df["book_rating"].min()
max = df["book_rating"].max()
y = df["book_rating"].apply(lambda x:(x-min) / (max-min))
```

**Cara Kerja**

**A. Menghitung Batas:**

```python
min = 0.0  # Rating minimum
max = 10.0 # Rating maximum
```

**B. Formula Min-Max Normalization:**

```python
normalized_value = (original_value - min) / (max - min)
```

**C. Contoh Transformasi:**

```python
# Rating asli ‚Üí Rating normalized
0  ‚Üí (0-0)/(10-0)  = 0.0
5  ‚Üí (5-0)/(10-0)  = 0.5
10 ‚Üí (10-0)/(10-0) = 1.0
```

**Train-Validation Split**

```python
split = int(0.85 * df.shape[0])
X_train, X_val, Y_train, Y_val = (
    x[:split],
    x[split:],
    y[:split],
    y[split:]
)
```

**Cara Kerja**

**A. Menghitung Split Point:**

```python
total_data = 1,149,780
split = int(0.85 * 1,149,780) = 977,313
```

**B. Pembagian Data:**

```python
# Training Set (85%)
X_train = x[0:977,313]     # Features training
Y_train = y[0:977,313]     # Target training

# Validation Set (15%)
X_val = x[977,313:end]     # Features validation  
Y_val = y[977,313:end]     # Target validation
```
Kode ini melakukan **persiapan akhir data** dengan shuffling untuk menghilangkan bias, normalisasi rating ke range 0-1 untuk stabilitas training, dan pembagian data 85:15 untuk training-validation yang optimal dalam collaborative filtering.

# Modeling
"""

class RecommenderBook(tf.keras.Model):
  def __init__(self, num_users, num_books, embedding_size, **kwargs):
    super(RecommenderBook, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_books=num_books
    self.embedding_size=embedding_size
    self.user_embedding = tf.keras.layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer="he_normal",
        embeddings_regularizer=tf.keras.regularizers.l2(0.00001)
    )
    self.user_bias = tf.keras.layers.Embedding(num_users, 1)
    self.book_embedding = tf.keras.layers.Embedding(
        num_books,
        embedding_size,
        embeddings_initializer="he_normal",
        embeddings_regularizer=tf.keras.regularizers.l2(0.00001)
      )
    self.book_bias=tf.keras.layers.Embedding(num_books, 1)

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:, 0])
    book_vector = self.book_embedding(inputs[:, 1])
    book_bias = self.book_bias(inputs[:, 1])

    dot_user_book = tf.tensordot(user_vector, book_vector, 2)

    x = dot_user_book + user_bias + book_bias

    return tf.nn.sigmoid(x) # activation sigmoid

"""**1. Struktur Kelas Model**

```python
class RecommenderBook(tf.keras.Model):
```

**Fungsi**

- **Inheritance**: Mewarisi dari `tf.keras.Model` untuk mendapatkan semua fitur training Keras
- **Custom Architecture**: Memungkinkan implementasi collaborative filtering yang disesuaikan

***

**2. Constructor (init)**

```python
def __init__(self, num_users, num_books, embedding_size, **kwargs):
    super(RecommenderBook, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_books = num_books
    self.embedding_size = embedding_size
```

**Parameter Input**

| Parameter | Fungsi | Contoh Nilai |
| --- | --- | --- |
| `num_users` | Jumlah user unik dalam dataset | 105,283 |
| `num_books` | Jumlah buku unik dalam dataset | 340,556 |
| `embedding_size` | Dimensi vektor embedding | 50-200 |

***

**3. Layer Embedding untuk User**

```python
self.user_embedding = tf.keras.layers.Embedding(
    num_users,
    embedding_size,
    embeddings_initializer="he_normal",
    embeddings_regularizer=tf.keras.regularizers.l2(0.00001)
)
self.user_bias = tf.keras.layers.Embedding(num_users, 1)
```

**A. User Embedding**

**Fungsi**: Mengkonversi user ID menjadi vektor dense yang merepresentasikan preferensi user

**Parameter:**

- **`num_users`**: Vocabulary size (jumlah user unik)
- **`embedding_size`**: Output dimension (dimensi vektor user)
- **`embeddings_initializer="he_normal"`**:
- Inisialisasi bobot dengan distribusi normal He
- Cocok untuk aktivasi ReLU dan turunannya
- Formula: `std = sqrt(2/fan_in)`
- **`embeddings_regularizer=tf.keras.regularizers.l2(0.00001)`**:
- L2 regularization untuk mencegah overfitting
- Penalty coefficient: 1e-5
- Menambahkan `0.00001 * sum(weights¬≤)` ke loss function

**B. User Bias**

**Fungsi**: Menangkap kecenderungan individual user (apakah cenderung memberi rating tinggi/rendah)

**Output Shape**: `(num_users, 1)` - satu nilai bias per user

***

**4. Layer Embedding untuk Book**

```python
self.book_embedding = tf.keras.layers.Embedding(
    num_books,
    embedding_size,
    embeddings_initializer="he_normal",
    embeddings_regularizer=tf.keras.regularizers.l2(0.00001)
)
self.book_bias = tf.keras.layers.Embedding(num_books, 1)
```

**A. Book Embedding**

**Fungsi**: Mengkonversi book ID menjadi vektor yang merepresentasikan karakteristik buku

**Parameter**: Sama dengan user embedding, namun dengan `num_books` sebagai vocabulary size

**B. Book Bias**

**Fungsi**: Menangkap kualitas inherent buku (apakah buku tersebut secara umum disukai atau tidak)

***

**5. Forward Pass (call method)**

```python
def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:, 0])
    book_vector = self.book_embedding(inputs[:, 1])
    book_bias = self.book_bias(inputs[:, 1])

    dot_user_book = tf.tensordot(user_vector, book_vector, 2)

    x = dot_user_book + user_bias + book_bias
    
    return tf.nn.sigmoid(x)
```

**Cara Kerja Step-by-Step**

**A. Input Parsing**

```python
# Input shape: (batch_size, 2)
# inputs[:,0] = user_encoded_ids
# inputs[:,1] = book_encoded_ids
```

**B. Embedding Lookup**

```python
user_vector = self.user_embedding(inputs[:,0])  # Shape: (batch_size, embedding_size)
book_vector = self.book_embedding(inputs[:,1])  # Shape: (batch_size, embedding_size)
user_bias = self.user_bias(inputs[:,0])         # Shape: (batch_size, 1)
book_bias = self.book_bias(inputs[:,1])         # Shape: (batch_size, 1)
```

**C. Dot Product (Similarity)**

```python
dot_user_book = tf.tensordot(user_vector, book_vector, 2)
```

- **Fungsi**: Menghitung similarity antara user dan book vectors
- **Parameter `2`**: Melakukan dot product pada 2 dimensi terakhir
- **Output**: Scalar similarity score per sample

**D. Bias Addition**

```python
x = dot_user_book + user_bias + book_bias
```

- **Menambahkan bias terms** untuk personalisasi lebih detail
- **Formula**: `rating = similarity + user_tendency + book_quality`

**E. Activation Function**

```python
return tf.nn.sigmoid(x)
```

- **Sigmoid**: Mengkonversi output ke range (0,1)
- **Sesuai dengan normalized rating** yang sudah dibuat sebelumnya

Model ini mengimplementasikan **Matrix Factorization** dengan **bias terms** menggunakan neural embeddings, yang memungkinkan pembelajaran representasi latent yang kaya untuk user dan book, serta dapat menangkap preferensi individual dan kualitas inherent item.
"""

model = RecommenderBook(num_users, num_books, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""**1. Inisialisasi Model**

```python
model = RecommenderBook(num_users, num_books, 50)
```

**Fungsi**

Membuat instance dari kelas `RecommenderBook` dengan parameter yang telah ditentukan.

**Parameter yang Digunakan**

| Parameter | Nilai | Penjelasan |
| --- | --- | --- |
| `num_users` | 105,283 | Jumlah user unik dalam dataset |
| `num_books` | 340,556 | Jumlah buku unik dalam dataset |
| `embedding_size` | 50 | Dimensi vektor embedding |

**Mengapa Embedding Size = 50?**

- **Keseimbangan**: Tidak terlalu kecil (underfitting) atau besar (overfitting)
- **Computational Efficiency**: Ukuran yang reasonable untuk training
- **Memory Usage**: Total parameters ‚âà (105,283 + 340,556) √ó 50 = ~22M parameters
- **Empirical Sweet Spot**: Umumnya 50-200 memberikan hasil optimal

Konfigurasi ini mengoptimalkan model untuk **collaborative filtering** dengan pendekatan yang **conservative** namun **effective**, menggunakan **BinaryCrossentropy** untuk training yang stabil dan **RMSE** untuk evaluasi yang interpretable.
"""

history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), batch_size=64, epochs=25)

"""Melakukan Training Untuk Model dengan menggunakan dataset yang sudah di split"""

plt.plot(history.history["root_mean_squared_error"])
plt.plot(history.history["val_root_mean_squared_error"])
plt.title("RMSE metrics plot")
plt.xlabel("Epochs")
plt.ylabel("RMSE")
plt.legend(["train","test"])
plt.savefig("evaluation.png", dpi=75)
plt.show()

"""**Fungsi Setiap Baris**

| Kode | Fungsi |
| --- | --- |
| `plt.plot(history.history["root_mean_squared_error"])` | Plot RMSE training |
| `plt.plot(history.history["val_root_mean_squared_error"])` | Plot RMSE validation |
| `plt.title("RMSE metrics plot")` | Judul grafik |
| `plt.xlabel("Epochs")` | Label sumbu X |
| `plt.ylabel("RMSE")` | Label sumbu Y |
| `plt.legend(["train","test"])` | Legenda biru=train, orange=test |
| `plt.savefig("evaluation.png", dpi=75)` | Simpan gambar |
| `plt.show()` | Tampilkan grafik |

***

**2. Analisis Output Grafik**

**A. Karakteristik Kurva Training (Biru)**

**Pola:**

- **Epoch 0-5**: Penurunan cepat dari ~0.40 ke ~0.35
- **Epoch 5-15**: Penurunan bertahap dari ~0.35 ke ~0.33
- **Epoch 15-25**: Penurunan lambat dari ~0.33 ke ~0.325

**Interpretasi:**

- **Fast Learning Phase**: Model cepat belajar pola dasar
- **Fine-tuning Phase**: Optimisasi detail
- **Convergence Phase**: Mendekati optimal point

**B. Karakteristik Kurva Validation (Orange)**

**Pola:**

- **Epoch 0-5**: Penurunan dari ~0.375 ke ~0.355
- **Epoch 5-15**: Penurunan bertahap ke ~0.345
- **Epoch 15-25**: Relatif stabil di ~0.340

**Interpretasi:**

- **Good Generalization**: Validation loss mengikuti training loss
- **No Overfitting**: Tidak ada divergence yang signifikan

***

**3. Evaluasi Performa Model**

**A. RMSE Values Analysis**

| Metric | Initial | Final | Improvement |
| --- | --- | --- | --- |
| **Training RMSE** | ~0.40 | ~0.325 | 18.75% |
| **Validation RMSE** | ~0.375 | ~0.340 | 9.33% |

**B. Konversi ke Skala Rating Asli**

```python
# RMSE dalam skala normalized [0,1]
final_train_rmse = 0.325
final_val_rmse = 0.340

# Konversi ke skala asli [0,10]
original_scale_train = final_train_rmse * 10 = 3.25
original_scale_val = final_val_rmse * 10 = 3.40
```

**Interpretasi**:

- Model memiliki **rata-rata error ¬±3.25** pada training set
- Model memiliki **rata-rata error ¬±3.40** pada validation set

***
Model menunjukkan **learning behavior yang sehat** dengan **potensi improvement** melalui hyperparameter tuning atau architectural changes. Cocok untuk **proof-of-concept** dan dapat digunakan untuk **basic recommendation system**.

# Hasil

## Memperoleh hasil rekomendasi
"""

book_df = book_new
df = pd.read_csv("/content/Ratings.csv")

user_id = df["User-ID"].sample(1).iloc[0]
readed_book_by_user = df[df["User-ID"] == user_id]

book_not_readed = book_df[~book_df["isbn"].isin(readed_book_by_user["ISBN"].values)]["isbn"]
book_not_readed = list(
    set(book_not_readed).intersection(set(isbn_encoded.keys()))
)
book_not_readed = [[isbn_encoded.get(x)] for x in book_not_readed]
user_encoder = user_encoded.get(user_id)
user_book_array = np.hstack(
    ([[user_encoder]] * len(book_not_readed), book_not_readed)
)

"""

**1. Inisialisasi Data**

```python
book_df = book_new
df = pd.read_csv("/content/Ratings.csv")
```

**Fungsi**

- **`book_df`**: Alias untuk dataframe buku (berisi mapping ISBN ‚Üî title)
- **`df`**: Load ulang dataset ratings asli dengan kolom nama original

**Mengapa Load Ulang?**

- Dataset asli memiliki kolom `"User-ID"` dan `"ISBN"` (dengan huruf kapital)
- Diperlukan untuk mencari user dan buku yang belum dibaca

***

**2. Pemilihan User Random**

```python
user_id = df["User-ID"].sample(1).iloc[0]
```

**Cara Kerja**

- **`.sample(1)`**: Mengambil 1 user secara random dari dataset
- **`.iloc[0]`**: Ekstrak nilai user_id dari pandas Series

**3. Identifikasi Buku yang Sudah Dibaca**

```python
readed_book_by_user = df[df["User-ID"] == user_id]
```

**Fungsi**

Mengfilter semua rating yang pernah diberikan oleh user terpilih

**Informasi yang Diperoleh**

- **Daftar buku** yang sudah pernah dibaca user
- **Rating** yang diberikan untuk setiap buku
- **Preferensi historis** user

***

**4. Identifikasi Buku yang Belum Dibaca**

```python
book_not_readed = book_df[~book_df["isbn"].isin(readed_book_by_user["ISBN"].values)]["isbn"]
```

**Cara Kerja**

**A. Ekstraksi ISBN yang Sudah Dibaca**

```python
readed_book_by_user["ISBN"].values
# Output: array(['034545104X', '0155061224', '0446520802', ...])
```

**B. Filter dengan Negasi (~)**

```python
~book_df["isbn"].isin(...)
# Mengambil buku yang TIDAK ada dalam daftar yang sudah dibaca
```

**C. Hasil**

```python
# book_not_readed berisi ISBN buku yang belum pernah dibaca user
```

***

**5. Filtering Buku yang Valid untuk Prediksi**

```python
book_not_readed = list(
    set(book_not_readed).intersection(set(isbn_encoded.keys()))
)
```

**Fungsi**

Memastikan hanya buku yang ada dalam **encoding dictionary** yang digunakan

**Cara Kerja**

- **`set(book_not_readed)`**: Convert ke set untuk operasi intersection
- **`set(isbn_encoded.keys())`**: Set semua ISBN yang ada dalam model
- **`.intersection()`**: Ambil irisan (buku yang ada di kedua set)

**Mengapa Perlu Filtering?**

- **Model Limitation**: Model hanya bisa prediksi untuk ISBN yang ada dalam training
- **Data Consistency**: Menghindari error saat encoding
- **Valid Predictions**: Memastikan semua prediksi valid

***

**6. Encoding User ID**

```python
user_encoder = user_encoded.get(user_id)
```

**Fungsi**

Mengkonversi `user_id` asli menjadi **encoded index** yang dipahami model

**Contoh**

```python
# Jika user_id = 276725
user_encoder = user_encoded.get(276725)  # Output: 0
```

***

**7. Persiapan Input Array untuk Model**

```python
book_not_readed = [[isbn_encoded.get(x)] for x in book_not_readed]
user_book_array = np.hstack(
    ([[user_encoder]] * len(book_not_readed), book_not_readed)
)
```

**A. Encoding ISBN**

```python
book_not_readed = [[isbn_encoded.get(x)] for x in book_not_readed]
```

**Fungsi**: Mengkonversi setiap ISBN menjadi encoded index dalam format list

**Contoh Transformasi**:

```python
# Before: ['034545104X', '0155061224', ...]
# After: [[0], [1], [2], ...]
```

**B. Pembuatan Input Array**

```python
user_book_array = np.hstack(
    ([[user_encoder]] * len(book_not_readed), book_not_readed)
)
```

**Cara Kerja**:

**Step 1**: Replikasi User Encoder

```python
[[user_encoder]] * len(book_not_readed)
# Jika user_encoder = 0 dan ada 1000 buku:
# [[0], [0], [0], ..., [0]]  # 1000 kali
```

**Step 2**: Horizontal Stack

```python
# Gabungkan user_id dengan setiap book_id
user_array = [[0], [0], [0], ...]     # User column
book_array = [[0], [1], [2], ...]     # Book column

# Result:
user_book_array = [[0, 0], [0, 1], [0, 2], ...]
```"""

ratings = model.predict(user_book_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_book_id = [
    isbn_decoded.get(book_not_readed[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Book with high ratings from user')
print('----' * 8)

top_book_user = (
    readed_book_by_user.sort_values(
        by = 'Book-Rating',
        ascending=False
    )
    .head(5)
    .ISBN.values
)

book_df_rows = book_df[book_df['isbn'].isin(top_book_user)].drop_duplicates()
for row in book_df_rows.itertuples():
    print(row.isbn, ':', row.title)

print('----' * 8)
print('Top 10 Book recommendation')
print('----' * 8)

recommended_book = book_df[book_df['isbn'].isin(recommended_book_id)].drop_duplicates()
for row in recommended_book.itertuples():
    print(row.isbn, ':', row.title)

"""Penjelasan Kode: Generasi Rekomendasi dan Output

**1. Prediksi Rating dengan Model**

```python
ratings = model.predict(user_book_array).flatten()
```

**Cara Kerja**

- **`model.predict()`**: Menjalankan forward pass model untuk semua kombinasi user-book
- **Input**: `user_book_array` dengan shape `(n_books, 2)` ‚Üí `[user_encoded, book_encoded]`
- **`.flatten()`**: Mengkonversi output 2D menjadi 1D array

**Parameter dan Fungsi**

| Parameter | Fungsi | Shape |
| --- | --- | --- |
| `user_book_array` | Input kombinasi user-book | `(n_books, 2)` |
| Output model | Predicted ratings (normalized 0-1) | `(n_books, 1)` |
| `.flatten()` | Konversi ke 1D array | `(n_books,)` |


***

**2. Identifikasi Top 10 Rekomendasi**

```python
top_ratings_indices = ratings.argsort()[-10:][::-1]
```

**Cara Kerja Step-by-Step**

**A. `.argsort()`**

```python
ratings = [0.23, 0.89, 0.45, 0.67, 0.91, 0.12]
ratings.argsort()  # Output: [5, 0, 2, 3, 1, 4]
# Mengurutkan INDEX berdasarkan nilai (ascending)
```

**B. `[-10:]`**

```python
# Mengambil 10 index terakhir (rating tertinggi)
top_10_indices = [1, 4]  # 2 teratas dari contoh
```

**C. `[::-1]`**

```python
# Membalik urutan menjadi descending
top_ratings_indices = [4, 1]  # Rating tertinggi ‚Üí terendah
```

**Hasil**

Index buku dengan 10 rating prediksi tertinggi, terurut descending

***

**3. Mapping ke ISBN Asli**

```python
recommended_book_id = [
    isbn_decoded.get(book_not_readed[x][0]) for x in top_ratings_indices
]
```

**Cara Kerja**

**A. Ekstraksi Encoded Book ID**

```python
# Untuk setiap index dalam top_ratings_indices:
x = top_ratings_indices[0]  # Index pertama
book_encoded_id = book_not_readed[x][0]  # Encoded book ID
```

**B. Decoding ke ISBN**

```python
isbn_original = isbn_decoded.get(book_encoded_id)
# Konversi encoded ID kembali ke ISBN asli
```

**Hasil**

List ISBN asli untuk 10 buku dengan prediksi rating tertinggi

***

**4. Menampilkan Preferensi User Historis**

```python
top_book_user = (
    readed_book_by_user.sort_values(
        by = 'Book-Rating',
        ascending=False
    )
    .head(5)
    .ISBN.values
)
```

**Parameter dan Fungsi**

| Parameter | Fungsi |
| --- | --- |
| `by='Book-Rating'` | Kolom untuk sorting |
| `ascending=False` | Urutan descending (rating tinggi ke rendah) |
| `.head(5)` | Ambil 5 buku teratas |
| `.ISBN.values` | Ekstrak array ISBN |

**Tujuan**

Menampilkan **konteks preferensi** user untuk memvalidasi rekomendasi

***

**5. Display Buku dengan Rating Tinggi dari User**

```python
book_df_rows = book_df[book_df['isbn'].isin(top_book_user)].drop_duplicates()
for row in book_df_rows.itertuples():
    print(row.isbn, ':', row.title)
```

**Cara Kerja**

- **`.isin(top_book_user)`**: Filter buku yang ada dalam top 5 user
- **`.drop_duplicates()`**: Hapus duplikasi jika ada
- **`.itertuples()`**: Iterator untuk setiap baris
- **`row.isbn`, `row.title`**: Akses kolom ISBN dan title

***

**6. Display Top 10 Rekomendasi**

```python
recommended_book = book_df[book_df['isbn'].isin(recommended_book_id)].drop_duplicates()
for row in recommended_book.itertuples():
    print(row.isbn, ':', row.title)
```

**Fungsi Sama dengan Section 5**

Menampilkan detail buku yang direkomendasikan model

***

**7. Analisis Output**

**A. User Profile (User 231210)**

```javascript
Book with high ratings from user:
1. The Advocate Adviser (Gay Columnist)
2. Physicians' Desk Reference 1998
3. Who's in a Family?
4. Times Family Atlas of the World
5. Real Kids, Real Adventures #1
```

**Analisis Preferensi**:

- **Diverse Interests**: Kesehatan, keluarga, petualangan
- **Non-fiction Tendency**: Referensi dan panduan
- **Family-oriented**: Buku tentang keluarga dan anak

**B. Model Recommendations**

```javascript
Top 10 Recommendations:
1. Harry Potter Series (4 buku)
2. Children's Poetry (Shel Silverstein)
3. Love You Forever
4. El Hobbit
5. A Kiss for Little Bear
```

**Analisis Rekomendasi**:

- **Genre Shift**: Model merekomendasikan fiksi anak
- **Pattern Recognition**: Menangkap preferensi family-friendly content
- **Popular Titles**: Buku-buku dengan rating tinggi secara umum

Sistem berhasil menghasilkan rekomendasi yang **relevan** dan **berkualitas**, meskipun ada **room for improvement** dalam hal personalisasi yang lebih detail. Model menunjukkan kemampuan untuk menangkap pola preferensi dan menghasilkan rekomendasi yang **meaningful** untuk user.

# **Evaluation**
"""

# 1. PERSIAPAN DATA TEST
print("\nüîß TAHAP 1: PERSIAPAN DATA TEST")
print("=" * 50)

# Buat data test dari validation data yang sudah ada
# Karena hanya ada train dan validation, kita gunakan validation sebagai test
X_test = X_val.copy()
Y_test = Y_val.copy()

print(f"‚úÖ Data test disiapkan dari validation set")
print(f"   ‚Ä¢ Jumlah sampel test: {len(X_test):,}")
print(f"   ‚Ä¢ Range rating (normalized): {Y_test.min():.4f} - {Y_test.max():.4f}")

# Informasi tentang normalisasi yang digunakan
print(f"\nüìã Informasi Normalisasi:")
print(f"   ‚Ä¢ Rating minimum original: {min}")
print(f"   ‚Ä¢ Rating maximum original: {max}")
print(f"   ‚Ä¢ Formula normalisasi: (x - {min}) / ({max} - {min})")

# 2. PREDIKSI PADA DATA TEST
print("\nüîç TAHAP 2: PREDIKSI PADA DATA TEST")
print("=" * 50)

# Lakukan prediksi pada data test
print("Melakukan prediksi pada dataset test...")
test_predictions = model.predict(X_test.values, batch_size=256, verbose=1)
test_predictions = test_predictions.flatten()

print(f"‚úÖ Prediksi selesai!")
print(f"   ‚Ä¢ Jumlah prediksi: {len(test_predictions):,}")
print(f"   ‚Ä¢ Range prediksi (normalized): {test_predictions.min():.4f} - {test_predictions.max():.4f}")
print(f"   ‚Ä¢ Mean prediksi (normalized): {test_predictions.mean():.4f}")

# 3. DENORMALISASI DATA
print("\nüîÑ TAHAP 3: DENORMALISASI KE SKALA ASLI")
print("=" * 50)

# Denormalisasi ke skala rating asli (0-10)
def denormalize_rating(normalized_rating, min_val, max_val):
    return normalized_rating * (max_val - min_val) + min_val

y_true_original = denormalize_rating(Y_test.values, min, max)
y_pred_original = denormalize_rating(test_predictions, min, max)

print(f"‚úÖ Denormalisasi selesai!")
print(f"   ‚Ä¢ Range rating asli: {y_true_original.min():.1f} - {y_true_original.max():.1f}")
print(f"   ‚Ä¢ Range prediksi asli: {y_pred_original.min():.1f} - {y_pred_original.max():.1f}")
print(f"   ‚Ä¢ Mean rating asli: {y_true_original.mean():.2f}")
print(f"   ‚Ä¢ Mean prediksi asli: {y_pred_original.mean():.2f}")

# 4. PERHITUNGAN METRIK EVALUASI
print("\nüìà TAHAP 4: PERHITUNGAN METRIK EVALUASI")
print("=" * 50)

# Hitung metrik pada skala asli
rmse_original = np.sqrt(mean_squared_error(y_true_original, y_pred_original))
mae_original = mean_absolute_error(y_true_original, y_pred_original)
mse_original = mean_squared_error(y_true_original, y_pred_original)
r2_original = r2_score(y_true_original, y_pred_original)

# Hitung metrik pada skala normalized
rmse_normalized = np.sqrt(mean_squared_error(Y_test.values, test_predictions))
mae_normalized = mean_absolute_error(Y_test.values, test_predictions)

# Hitung metrik tambahan
def mean_absolute_percentage_error(y_true, y_pred):
    return np.mean(np.abs((y_true - y_pred) / np.maximum(np.abs(y_true), 1e-8))) * 100

mape = mean_absolute_percentage_error(y_true_original, y_pred_original)

# Hitung akurasi prediksi dalam toleransi tertentu
tolerance_1 = np.mean(np.abs(y_true_original - y_pred_original) <= 1.0) * 100  # Dalam 1 poin
tolerance_2 = np.mean(np.abs(y_true_original - y_pred_original) <= 2.0) * 100  # Dalam 2 poin

print("üìä HASIL EVALUASI METRIK (Skala Asli 0-10):")
print("-" * 50)
print(f"Root Mean Squared Error (RMSE)    : {rmse_original:.4f}")
print(f"Mean Absolute Error (MAE)         : {mae_original:.4f}")
print(f"Mean Squared Error (MSE)          : {mse_original:.4f}")
print(f"R¬≤ Score                          : {r2_original:.4f}")
print(f"Mean Absolute Percentage Error    : {mape:.2f}%")

print(f"\nüìä HASIL EVALUASI METRIK (Skala Normalized 0-1):")
print("-" * 50)
print(f"RMSE (Normalized)                 : {rmse_normalized:.4f}")
print(f"MAE (Normalized)                  : {mae_normalized:.4f}")

print(f"\nüéØ AKURASI PREDIKSI:")
print("-" * 50)
print(f"Akurasi dalam toleransi ¬±1 poin   : {tolerance_1:.2f}%")
print(f"Akurasi dalam toleransi ¬±2 poin   : {tolerance_2:.2f}%")

# 5. VISUALISASI PERFORMA MODEL
print("\nüìä TAHAP 5: VISUALISASI PERFORMA MODEL")
print("=" * 50)

# Setup untuk plotting
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# Plot 1: Actual vs Predicted Scatter Plot (Skala Asli)
axes[0,0].scatter(y_true_original, y_pred_original, alpha=0.5, s=1, color='blue')
axes[0,0].plot([y_true_original.min(), y_true_original.max()],
               [y_true_original.min(), y_true_original.max()], 'r--', lw=2)
axes[0,0].set_xlabel('Actual Rating')
axes[0,0].set_ylabel('Predicted Rating')
axes[0,0].set_title(f'Actual vs Predicted Ratings (Original Scale)\n(R¬≤ = {r2_original:.4f})')
axes[0,0].grid(True, alpha=0.3)

# Plot 2: Residual Plot
residuals = y_true_original - y_pred_original
axes[0,1].scatter(y_pred_original, residuals, alpha=0.5, s=1, color='green')
axes[0,1].axhline(y=0, color='r', linestyle='--')
axes[0,1].set_xlabel('Predicted Rating')
axes[0,1].set_ylabel('Residuals')
axes[0,1].set_title(f'Residual Plot\n(MAE = {mae_original:.4f})')
axes[0,1].grid(True, alpha=0.3)

# Plot 3: Distribution of Errors
axes[1,0].hist(residuals, bins=50, alpha=0.7, edgecolor='black', color='orange')
axes[1,0].axvline(x=0, color='r', linestyle='--')
axes[1,0].set_xlabel('Prediction Error')
axes[1,0].set_ylabel('Frequency')
axes[1,0].set_title(f'Distribution of Prediction Errors\n(RMSE = {rmse_original:.4f})')
axes[1,0].grid(True, alpha=0.3)

# Plot 4: Training History
axes[1,1].plot(history.history['root_mean_squared_error'], label='Training RMSE', color='blue')
axes[1,1].plot(history.history['val_root_mean_squared_error'], label='Validation RMSE', color='orange')
axes[1,1].set_xlabel('Epochs')
axes[1,1].set_ylabel('RMSE (Normalized)')
axes[1,1].set_title('Training History - RMSE')
axes[1,1].legend()
axes[1,1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig("model_evaluation_comprehensive.png", dpi=150, bbox_inches='tight')
plt.show()

# 6. ANALISIS DISTRIBUSI RATING
print("\nüìà TAHAP 6: ANALISIS DISTRIBUSI RATING")
print("=" * 50)

# Analisis distribusi rating
fig, axes = plt.subplots(1, 2, figsize=(15, 5))

# Distribusi rating aktual vs prediksi
axes[0].hist(y_true_original, bins=20, alpha=0.7, label='Actual', density=True, color='blue')
axes[0].hist(y_pred_original, bins=20, alpha=0.7, label='Predicted', density=True, color='red')
axes[0].set_xlabel('Rating')
axes[0].set_ylabel('Density')
axes[0].set_title('Distribution Comparison: Actual vs Predicted')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# Box plot perbandingan
data_for_boxplot = pd.DataFrame({
    'Actual': y_true_original,
    'Predicted': y_pred_original
})
data_melted = data_for_boxplot.melt(var_name='Type', value_name='Rating')
sns.boxplot(data=data_melted, x='Type', y='Rating', ax=axes[1])
axes[1].set_title('Box Plot: Actual vs Predicted Ratings')
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig("rating_distribution_analysis.png", dpi=150, bbox_inches='tight')
plt.show()

# Statistik deskriptif
print("\nüìä STATISTIK DESKRIPTIF:")
print("-" * 40)
stats_comparison = pd.DataFrame({
    'Actual': [y_true_original.mean(), y_true_original.std(), y_true_original.min(), y_true_original.max()],
    'Predicted': [y_pred_original.mean(), y_pred_original.std(), y_pred_original.min(), y_pred_original.max()]
}, index=['Mean', 'Std', 'Min', 'Max'])

print(stats_comparison.round(4))

# 7. EVALUASI BERDASARKAN KATEGORI RATING
print("\nüéØ TAHAP 7: EVALUASI BERDASARKAN KATEGORI RATING")
print("=" * 50)

# Kategorisasi rating berdasarkan skala 0-10
def categorize_rating(rating):
    if rating <= 3:
        return 'Low (0-3)'
    elif rating <= 6:
        return 'Medium (4-6)'
    else:
        return 'High (7-10)'

# Buat kategori
y_true_cat = [categorize_rating(r) for r in y_true_original]
y_pred_cat = [categorize_rating(r) for r in y_pred_original]

# Hitung MAE per kategori
categories = ['Low (0-3)', 'Medium (4-6)', 'High (7-10)']
category_performance = {}

for category in categories:
    mask = np.array([cat == category for cat in y_true_cat])
    if any(mask):
        cat_true = y_true_original[mask]
        cat_pred = y_pred_original[mask]
        cat_mae = mean_absolute_error(cat_true, cat_pred)
        cat_rmse = np.sqrt(mean_squared_error(cat_true, cat_pred))
        category_performance[category] = {
            'count': len(cat_true),
            'mae': cat_mae,
            'rmse': cat_rmse
        }

print("üìä PERFORMA PER KATEGORI RATING:")
print("-" * 50)
for category, metrics in category_performance.items():
    print(f"{category}:")
    print(f"  ‚Ä¢ Jumlah sampel: {metrics['count']:,}")
    print(f"  ‚Ä¢ MAE: {metrics['mae']:.4f}")
    print(f"  ‚Ä¢ RMSE: {metrics['rmse']:.4f}")
    print()

# 8. CONFUSION MATRIX UNTUK KATEGORI
print("\nüîç TAHAP 8: CONFUSION MATRIX KATEGORI RATING")
print("=" * 50)

from sklearn.metrics import confusion_matrix, classification_report

# Buat confusion matrix
cm = confusion_matrix(y_true_cat, y_pred_cat, labels=categories)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=categories, yticklabels=categories)
plt.title('Confusion Matrix - Rating Categories')
plt.xlabel('Predicted Category')
plt.ylabel('Actual Category')
plt.tight_layout()
plt.savefig("confusion_matrix_categories.png", dpi=150, bbox_inches='tight')
plt.show()

# Classification report
print("\nüìã CLASSIFICATION REPORT:")
print("-" * 50)
print(classification_report(y_true_cat, y_pred_cat, labels=categories))

# 9. ANALISIS PERFORMA TRAINING
print("\nüìà TAHAP 9: ANALISIS PERFORMA TRAINING")
print("=" * 50)

# Analisis training history yang lebih detail
final_train_rmse = history.history['root_mean_squared_error'][-1]
final_val_rmse = history.history['val_root_mean_squared_error'][-1]
final_train_loss = history.history['loss'][-1]
final_val_loss = history.history['val_loss'][-1]

print(f"üìä METRIK TRAINING FINAL:")
print("-" * 40)
print(f"Training RMSE (Normalized)        : {final_train_rmse:.4f}")
print(f"Validation RMSE (Normalized)      : {final_val_rmse:.4f}")
print(f"Training Loss                     : {final_train_loss:.4f}")
print(f"Validation Loss                   : {final_val_loss:.4f}")

# Cek overfitting
rmse_diff = abs(final_train_rmse - final_val_rmse)
loss_diff = abs(final_train_loss - final_val_loss)

print(f"\nüîç ANALISIS OVERFITTING:")
print("-" * 40)
print(f"Selisih RMSE (Train-Val)          : {rmse_diff:.4f}")
print(f"Selisih Loss (Train-Val)          : {loss_diff:.4f}")

if rmse_diff < 0.02 and loss_diff < 0.02:
    print("‚úÖ Model tidak mengalami overfitting")
elif rmse_diff < 0.05 and loss_diff < 0.05:
    print("‚ö†Ô∏è  Model mengalami sedikit overfitting")
else:
    print("‚ùå Model mengalami overfitting")

# 10. RINGKASAN EVALUASI
print("\nüéØ RINGKASAN EVALUASI MODEL")
print("=" * 60)

# Interpretasi performa
def interpret_rmse(rmse, scale=10):
    percentage = (rmse / scale) * 100
    if percentage < 10:
        return "Excellent"
    elif percentage < 15:
        return "Very Good"
    elif percentage < 20:
        return "Good"
    elif percentage < 25:
        return "Fair"
    else:
        return "Poor"

def interpret_r2(r2):
    if r2 >= 0.9:
        return "Excellent"
    elif r2 >= 0.8:
        return "Very Good"
    elif r2 >= 0.7:
        return "Good"
    elif r2 >= 0.6:
        return "Fair"
    else:
        return "Poor"

rmse_interpretation = interpret_rmse(rmse_original)
r2_interpretation = interpret_r2(r2_original)

print("üìä METRIK EVALUASI UTAMA:")
print("-" * 40)
print(f"RMSE (Skala 0-10)           : {rmse_original:.4f} ({rmse_interpretation})")
print(f"MAE (Skala 0-10)            : {mae_original:.4f}")
print(f"R¬≤ Score                    : {r2_original:.4f} ({r2_interpretation})")
print(f"MAPE                        : {mape:.2f}%")

print(f"\nüéØ AKURASI PREDIKSI:")
print("-" * 40)
print(f"Dalam toleransi ¬±1 poin     : {tolerance_1:.2f}%")
print(f"Dalam toleransi ¬±2 poin     : {tolerance_2:.2f}%")

print(f"\nüí° INTERPRETASI:")
print("-" * 40)
if rmse_original <= 1.5:
    print("‚úÖ Model memiliki performa SANGAT BAIK untuk prediksi rating")
elif rmse_original <= 2.0:
    print("‚úÖ Model memiliki performa BAIK untuk prediksi rating")
elif rmse_original <= 2.5:
    print("‚ö†Ô∏è  Model memiliki performa CUKUP untuk prediksi rating")
else:
    print("‚ùå Model perlu perbaikan untuk meningkatkan akurasi prediksi")

if r2_original >= 0.7:
    print("‚úÖ Model dapat menjelaskan variasi rating dengan baik")
elif r2_original >= 0.5:
    print("‚ö†Ô∏è  Model dapat menjelaskan sebagian variasi rating")
else:
    print("‚ùå Model kesulitan menjelaskan variasi rating")

print(f"\nüöÄ STATUS: Evaluasi model selesai!")

# 11. SIMPAN HASIL EVALUASI
print("\nüíæ MENYIMPAN HASIL EVALUASI")
print("=" * 50)

# Buat summary hasil evaluasi
evaluation_results = {
    'Model': 'Collaborative Filtering (Neural Matrix Factorization)',
    'Dataset_Size': len(Y_test),
    'Embedding_Size': 50,
    'Epochs': 25,
    'RMSE_Original_Scale': rmse_original,
    'MAE_Original_Scale': mae_original,
    'R2_Score': r2_original,
    'MAPE': mape,
    'Accuracy_1_Point': tolerance_1,
    'Accuracy_2_Point': tolerance_2,
    'RMSE_Normalized': rmse_normalized,
    'MAE_Normalized': mae_normalized,
    'Final_Train_RMSE': final_train_rmse,
    'Final_Val_RMSE': final_val_rmse,
    'RMSE_Interpretation': rmse_interpretation,
    'R2_Interpretation': r2_interpretation
}

# Simpan ke DataFrame
results_df = pd.DataFrame([evaluation_results])
print("‚úÖ Hasil evaluasi berhasil disimpan!")
print("\nüìã Summary Hasil Evaluasi:")
display(results_df)

"""# Penjelasan Evaluasi Model Collaborative Filtering

## 1. Fungsi dan Tujuan Evaluasi

### **Tujuan Utama Evaluasi:**

Evaluasi model bertujuan untuk mengukur seberapa baik sistem rekomendasi Collaborative Filtering dapat **menjawab problem statement** yang telah dirumuskan:

1. **Mempercepat proses pencarian buku**: Dengan mengukur akurasi prediksi rating, kita dapat memastikan sistem memberikan rekomendasi yang relevan, sehingga pengguna tidak perlu menghabiskan waktu mencari buku secara manual.

2. **Mengembangkan sistem rekomendasi yang akurat**: Evaluasi memvalidasi kemampuan model dalam memprediksi preferensi pengguna berdasarkan data rating historis.

### **Fungsi Evaluasi:**

- **Validasi Performa**: Memastikan model dapat memprediksi rating dengan akurat
- **Deteksi Overfitting**: Mengidentifikasi apakah model terlalu spesifik pada data training
- **Interpretasi Bisnis**: Menerjemahkan metrik teknis ke dalam konteks bisnis yang dapat dipahami
- **Optimasi Model**: Memberikan insight untuk perbaikan model di masa depan

***

## 2. Cara Kerja Sistem Evaluasi

### **Alur Kerja Evaluasi:**

```javascript
Data Test (X_val, Y_val) ‚Üí Prediksi Model ‚Üí Denormalisasi ‚Üí Perhitungan Metrik ‚Üí Interpretasi
```

### **Proses Detail:**

1. **Persiapan Data Test**:

- Menggunakan validation set sebagai data test
- Data berisi pasangan (user_encoded, isbn_encoded) dan rating yang dinormalisasi

2. **Prediksi Model**:

- Model memprediksi rating untuk pasangan user-book pada data test
- Output berupa nilai probabilitas (0-1) karena menggunakan sigmoid activation

3. **Denormalisasi**:

- Mengkonversi hasil prediksi dari skala 0-1 kembali ke skala asli 0-10
- Formula: `rating_asli = normalized_rating √ó (max - min) + min`

4. **Perhitungan Metrik**:

- Menghitung berbagai metrik evaluasi pada skala asli dan normalized
- Membandingkan prediksi dengan rating aktual

5. **Analisis dan Interpretasi**:

- Mengkategorikan performa model
- Memberikan rekomendasi perbaikan

***

## 3. Parameter dan Metrik yang Digunakan

### **A. Parameter Normalisasi:**

| Parameter | Nilai | Fungsi |
| --- | --- | --- |
| `min` | Rating minimum (0) | Batas bawah normalisasi |
| `max` | Rating maximum (10) | Batas atas normalisasi |
| **Formula** | `(x - min) / (max - min)` | Mengkonversi rating ke skala 0-1 |

**Fungsi Normalisasi:**

- Menstandardisasi input untuk model neural network
- Membantu konvergensi training yang lebih stabil
- Memungkinkan penggunaan sigmoid activation function

### **B. Metrik Evaluasi Utama:**

#### **1. Root Mean Squared Error (RMSE)**

```python
rmse = ‚àö(Œ£(y_true - y_pred)¬≤/n)
```

- **Fungsi**: Mengukur rata-rata kesalahan prediksi dengan memberikan penalti lebih besar pada error yang besar
- **Interpretasi**: Semakin rendah semakin baik
- **Skala**: Sama dengan skala rating asli (0-10)
- **Keunggulan**: Sensitif terhadap outlier, cocok untuk deteksi prediksi yang sangat meleset

#### **2. Mean Absolute Error (MAE)**

```python
mae = Œ£|y_true - y_pred|/n
```

- **Fungsi**: Mengukur rata-rata absolut kesalahan prediksi
- **Interpretasi**: Rata-rata seberapa jauh prediksi dari nilai sebenarnya
- **Keunggulan**: Lebih robust terhadap outlier dibanding RMSE
- **Konteks Bisnis**: Menunjukkan rata-rata kesalahan prediksi rating dalam poin

#### **3. R¬≤ Score (Coefficient of Determination)**

```python
r2 = 1 - (SS_res / SS_tot)
```

- **Fungsi**: Mengukur seberapa baik model menjelaskan variabilitas data
- **Range**: -‚àû hingga 1 (1 = perfect fit)
- **Interpretasi**:
- 0.9-1.0: Excellent
- 0.8-0.9: Very Good
- 0.7-0.8: Good
- <0.7: Perlu perbaikan

#### **4. Mean Absolute Percentage Error (MAPE)**

```python
mape = (100/n) √ó Œ£|((y_true - y_pred)/y_true)|
```

- **Fungsi**: Mengukur kesalahan dalam bentuk persentase
- **Keunggulan**: Scale-independent, mudah diinterpretasi bisnis
- **Interpretasi**: Persentase rata-rata kesalahan prediksi

### **C. Metrik Akurasi Toleransi:**

#### **Akurasi ¬±1 Poin**

```python
accuracy_1 = (jumlah_prediksi_dalam_toleransi_1_poin / total_prediksi) √ó 100%
```

- **Fungsi**: Mengukur persentase prediksi yang akurat dalam toleransi ¬±1 poin rating
- **Konteks Bisnis**: Menunjukkan seberapa sering sistem memberikan rekomendasi yang "hampir tepat"

#### **Akurasi ¬±2 Poin**

```python
accuracy_2 = (jumlah_prediksi_dalam_toleransi_2_poin / total_prediksi) √ó 100%
```

- **Fungsi**: Mengukur persentase prediksi yang dapat diterima dalam toleransi ¬±2 poin
- **Konteks Bisnis**: Standar minimum untuk rekomendasi yang "cukup baik"

***

## 4. Analisis Kategori Rating

### **Kategorisasi Rating:**

- **Low (0-3)**: Buku yang tidak disukai
- **Medium (4-6)**: Buku dengan rating sedang
- **High (7-10)**: Buku yang sangat disukai

### **Fungsi Analisis Kategori:**

1. **Identifikasi Bias Model**: Apakah model lebih baik memprediksi kategori tertentu
2. **Strategi Rekomendasi**: Fokus pada kategori High untuk rekomendasi terbaik
3. **Validasi Bisnis**: Memastikan model dapat membedakan preferensi pengguna

***

## 5. Menjawab Problem Statement

### **Problem 1: Mempercepat Proses Pencarian Buku**

**Solusi melalui Evaluasi:**

- **Metrik Akurasi Toleransi**: Memastikan ‚â•80% prediksi dalam toleransi ¬±2 poin
- **RMSE ‚â§ 2.0**: Menjamin prediksi yang cukup akurat untuk rekomendasi
- **Analisis Kategori High**: Fokus pada buku dengan rating tinggi untuk rekomendasi prioritas

**Cara Kerja:**

1. Sistem memprediksi rating untuk buku yang belum dibaca pengguna
2. Mengurutkan buku berdasarkan prediksi rating tertinggi
3. Memberikan top-10 rekomendasi yang paling relevan
4. **Hasil**: Pengguna tidak perlu browsing manual, langsung mendapat rekomendasi personal

### **Problem 2: Sistem Rekomendasi Berdasarkan Data Penilaian**

**Solusi melalui Evaluasi:**

- **R¬≤ Score ‚â• 0.7**: Memastikan model dapat menangkap pola preferensi pengguna
- **MAE ‚â§ 1.5**: Menjamin prediksi rating yang akurat
- **Confusion Matrix**: Validasi kemampuan model membedakan preferensi

**Cara Kerja:**

1. **Collaborative Filtering**: Menganalisis pola rating pengguna serupa
2. **Matrix Factorization**: Mengidentifikasi faktor laten yang mempengaruhi preferensi
3. **Embedding Learning**: Mempelajari representasi user dan book dalam ruang laten
4. **Prediksi Rating**: Menghitung kemungkinan rating untuk buku yang belum dibaca

***

## 6. Interpretasi Hasil Evaluasi

### **Standar Performa yang Baik:**

| Metrik | Excellent | Good | Fair | Poor |
| --- | --- | --- | --- | --- |
| RMSE | ‚â§ 1.5 | ‚â§ 2.0 | ‚â§ 2.5 | > 2.5 |
| R¬≤ | ‚â• 0.9 | ‚â• 0.7 | ‚â• 0.5 | < 0.5 |
| Akurasi ¬±2 | ‚â• 90% | ‚â• 80% | ‚â• 70% | < 70% |

### **Konteks Bisnis:**

- **RMSE 1.5**: Rata-rata kesalahan prediksi 1.5 poin dari rating sebenarnya
- **Akurasi 80%**: 8 dari 10 rekomendasi memiliki rating yang cukup akurat
- **R¬≤ 0.7**: Model dapat menjelaskan 70% variasi preferensi pengguna

### **Dampak pada Problem Statement:**

1. **Efisiensi Pencarian**: Model dengan performa baik dapat mengurangi waktu pencarian dari jam menjadi detik
2. **Akurasi Rekomendasi**: Sistem dapat memprediksi preferensi dengan tingkat kepercayaan tinggi
3. **Personalisasi**: Setiap pengguna mendapat rekomendasi yang disesuaikan dengan riwayat rating mereka

***

## 7. Kesimpulan Evaluasi

### **Validasi Solusi:**

Sistem evaluasi memvalidasi bahwa model Collaborative Filtering dapat:

1. ‚úÖ **Mempercepat pencarian**: Memberikan rekomendasi instan berdasarkan preferensi
2. ‚úÖ **Memanfaatkan data rating**: Menggunakan pola rating historis untuk prediksi
3. ‚úÖ **Personalisasi**: Memberikan rekomendasi yang disesuaikan per pengguna
4. ‚úÖ **Akurasi tinggi**: Prediksi rating dengan tingkat kesalahan yang dapat diterima

### **Kontribusi terhadap Problem Statement:**

- **Efisiensi**: Mengurangi waktu pencarian buku dari manual browsing menjadi rekomendasi otomatis
- **Akurasi**: Memastikan rekomendasi sesuai dengan preferensi pengguna berdasarkan data historis
- **Skalabilitas**: Sistem dapat menangani jutaan interaksi user-book untuk memberikan rekomendasi real-time

# Penjelasan Output Evaluasi Model Collaborative Filtering

## 1. Analisis Output Evaluasi

### **A. Persiapan Data Test**

```javascript
‚úÖ Data test disiapkan dari validation set
   ‚Ä¢ Jumlah sampel test: 172,467
   ‚Ä¢ Range rating (normalized): 0.0000 - 1.0000
```

**Penjelasan Output:**

- **172,467 sampel**: Dataset test yang cukup besar untuk evaluasi yang robust
- **Range 0-1**: Konfirmasi bahwa normalisasi berhasil mengkonversi rating ke skala 0-1
- **Normalisasi formula**: `(x - 0) / (10 - 0) = x/10` - sederhana karena rating asli sudah 0-10

### **B. Hasil Prediksi Model**

```javascript
‚úÖ Prediksi selesai!
   ‚Ä¢ Range prediksi (normalized): 0.0000 - 0.8562
   ‚Ä¢ Mean prediksi (normalized): 0.1548
```

**Analisis Kritis:**

- **Range prediksi hanya 0-0.86**: Model tidak pernah memprediksi rating maksimal (setara 8.6/10)
- **Mean prediksi 0.15**: Model cenderung memprediksi rating rendah (setara 1.5/10)
- **‚ö†Ô∏è Problem**: Model mengalami **underprediction bias** - selalu memprediksi lebih rendah

### **C. Denormalisasi ke Skala Asli**

```javascript
‚úÖ Denormalisasi selesai!
   ‚Ä¢ Mean rating asli: 2.87
   ‚Ä¢ Mean prediksi asli: 1.55
```

**Interpretasi:**

- **Gap signifikan**: Selisih 1.32 poin antara rata-rata actual vs predicted
- **Bias sistematis**: Model konsisten memprediksi lebih rendah dari kenyataan
- **Implikasi bisnis**: Sistem akan meremehkan preferensi pengguna

***

## 2. Analisis Metrik Evaluasi

### **A. Metrik Utama - Performa Buruk**

```javascript
RMSE (Skala 0-10): 3.7085 (Poor)
MAE (Skala 0-10): 2.7243
R¬≤ Score: 0.0735 (Poor)
```

**Penjelasan Detail:**

#### **RMSE = 3.71**

- **Interpretasi**: Rata-rata kesalahan prediksi 3.71 poin dari rating sebenarnya
- **Konteks**: Pada skala 0-10, ini adalah kesalahan 37% - sangat tinggi
- **Standar industri**: RMSE yang baik untuk sistem rekomendasi biasanya <2.0
- **‚ö†Ô∏è Masalah**: Model tidak reliable untuk prediksi rating

#### **MAE = 2.72**

- **Interpretasi**: Rata-rata absolut kesalahan 2.72 poin
- **Konteks bisnis**: Jika user sebenarnya rating 8, model prediksi ~5.3
- **Dampak**: Rekomendasi tidak akurat, user mungkin tidak puas

#### **R¬≤ = 0.0735**

- **Interpretasi**: Model hanya menjelaskan 7.35% variasi rating
- **Artinya**: 92.65% variasi tidak dapat dijelaskan model
- **‚ö†Ô∏è Masalah kritis**: Model hampir tidak berguna untuk prediksi

### **B. MAPE Anomali**

```javascript
MAPE: 6987152963.16%
```

**Penjelasan Anomali:**

- **Penyebab**: Division by zero atau nilai rating actual = 0
- **Formula MAPE**: `|actual - predicted| / actual √ó 100%`
- **Masalah**: Ketika actual = 0, pembagian menghasilkan infinity
- **Solusi**: MAPE tidak cocok untuk data dengan nilai 0

### **C. Akurasi Toleransi**

```javascript
Akurasi dalam toleransi ¬±1 poin: 33.81%
Akurasi dalam toleransi ¬±2 poin: 54.04%
```

**Interpretasi:**

- **33.81% dalam ¬±1**: Hanya 1 dari 3 prediksi yang "hampir benar"
- **54.04% dalam ¬±2**: Hanya setengah prediksi yang "cukup dapat diterima"
- **Standar industri**: Minimal 80% untuk ¬±2 poin
- **‚ö†Ô∏è Kesimpulan**: Akurasi tidak memadai untuk sistem produksi

***

## 3. Analisis Distribusi dan Visualisasi

### **A. Statistik Deskriptif**

```javascript
       Actual  Predicted
Mean   2.8666     1.5477
Std    3.8528     1.2013
Min    0.0000     0.0003
Max   10.0000     8.5624
```

**Analisis Mendalam:**

#### **Perbedaan Mean (2.87 vs 1.55)**

- **Gap**: 1.32 poin - bias sistematis yang signifikan
- **Penyebab**: Model terlalu konservatif dalam prediksi
- **Dampak**: Sistem akan meremehkan preferensi user

#### **Perbedaan Standard Deviation (3.85 vs 1.20)**

- **Actual**: Variasi tinggi (0-10) - data natural
- **Predicted**: Variasi rendah (0-1.2) - model tidak confident
- **‚ö†Ô∏è Problem**: Model tidak dapat menangkap diversitas preferensi

#### **Range Prediction (0-8.56)**

- **Missing high ratings**: Model tidak pernah prediksi >8.6
- **Implikasi**: Buku bagus tidak akan direkomendasikan dengan confidence tinggi

### **B. Analisis Visualisasi**

#### **Distribution Plot:**

- **Actual**: Distribusi U-shaped (banyak rating 0 dan tinggi)
- **Predicted**: Distribusi exponential decay (dominasi rating rendah)
- **‚ö†Ô∏è Masalah**: Model tidak memahami pola preferensi user yang sebenarnya

#### **Box Plot:**

- **Actual**: Median ~7, quartile range luas
- **Predicted**: Median ~1, range sangat sempit
- **Interpretasi**: Model terlalu bias ke rating rendah

***

## 4. Analisis Per Kategori Rating

### **A. Performance Per Kategori**

```javascript
Low (0-3):   MAE: 1.12, RMSE: 1.44  ‚úÖ Baik
Medium (4-6): MAE: 3.25, RMSE: 3.44  ‚ö†Ô∏è Sedang  
High (7-10):  MAE: 6.14, RMSE: 6.35  ‚ùå Buruk
```

**Insight Penting:**

- **Model baik untuk rating rendah**: Error hanya 1.12 poin
- **Model buruk untuk rating tinggi**: Error 6.14 poin
- **Pola**: Semakin tinggi rating actual, semakin buruk prediksi
- **‚ö†Ô∏è Implikasi**: Sistem tidak dapat mengidentifikasi buku berkualitas tinggi

### **B. Confusion Matrix Analysis**

```javascript
              precision    recall  f1-score   support
Low (0-3)       0.67      0.97      0.79    108977
Medium (4-6)    0.14      0.13      0.13     14567  
High (7-10)     0.91      0.03      0.06     48923
```

**Analisis Detail:**

#### **Low Category (0-3):**

- **Recall 97%**: Model sangat baik mendeteksi rating rendah
- **Precision 67%**: 2/3 prediksi "low" benar
- **Interpretasi**: Model bias memprediksi semua sebagai "low"

#### **High Category (7-10):**

- **Recall 3%**: Model hampir tidak pernah deteksi rating tinggi
- **Precision 91%**: Jika prediksi "high", biasanya benar
- **‚ö†Ô∏è Problem kritis**: Model gagal mengidentifikasi preferensi tinggi

#### **Overall Accuracy: 63%**

- **Interpretation**: 6 dari 10 kategori prediksi benar
- **Bias**: Akurasi tinggi karena dominasi prediksi "low"

***

## 5. Analisis Training Performance

### **A. Overfitting Detection**

```javascript
Training RMSE: 0.3230
Validation RMSE: 0.3379
Selisih: 0.0150
‚ö†Ô∏è Model mengalami sedikit overfitting
```

**Interpretasi:**

- **Gap kecil**: 0.015 - overfitting minimal
- **Bukan masalah utama**: Performa buruk bukan karena overfitting
- **Root cause**: Model capacity atau architecture yang tidak optimal

***

## 6. Diagnosis Masalah dan Solusi

### **A. Identifikasi Masalah Utama**

#### **1. Underprediction Bias**

- **Gejala**: Mean predicted (1.55) << Mean actual (2.87)
- **Penyebab**: Sigmoid activation + loss function combination
- **Dampak**: Sistem meremehkan semua preferensi

#### **2. Limited Prediction Range**

- **Gejala**: Max prediction hanya 8.56/10
- **Penyebab**: Model tidak confident untuk prediksi tinggi
- **Dampak**: Buku berkualitas tidak direkomendasikan optimal

#### **3. Poor High-Rating Detection**

- **Gejala**: Recall 3% untuk kategori High
- **Penyebab**: Model tidak belajar pattern untuk rating tinggi
- **Dampak**: Gagal mengidentifikasi buku yang benar-benar disukai

### **B. Rekomendasi Perbaikan**

#### **1. Architecture Improvements**

```python
# Tambahkan layer dan regularization
model = Sequential([
    Embedding(...),
    Dropout(0.3),
    Dense(128, activation='relu'),
    Dense(64, activation='relu'),
    Dense(1, activation='linear')  # Ganti sigmoid dengan linear
])
```

#### **2. Loss Function Optimization**

```python
# Ganti dari BinaryCrossentropy ke MSE
model.compile(
    loss='mse',  # Lebih cocok untuk regression
    optimizer=Adam(learning_rate=1e-3),
    metrics=['mae', 'rmse']
)
```

#### **3. Data Balancing**

```python
# Balance dataset per kategori rating
from sklearn.utils.class_weight import compute_class_weight
class_weights = compute_class_weight('balanced', ...)
```

***

## 7. Menjawab Problem Statement (Revisi)

### **Problem 1: Mempercepat Proses Pencarian Buku**

**Status Saat Ini: ‚ùå BELUM TERCAPAI**

**Analisis:**

- **Akurasi rendah (54% dalam ¬±2)**: Rekomendasi tidak reliable
- **Bias ke rating rendah**: Sistem tidak akan merekomendasikan buku bagus
- **Dampak**: User masih perlu manual search karena rekomendasi tidak akurat

**Solusi yang Diperlukan:**

- Tingkatkan akurasi minimal 80% dalam toleransi ¬±2
- Perbaiki bias underprediction
- Optimasi untuk deteksi rating tinggi

### **Problem 2: Sistem Rekomendasi Berdasarkan Data Penilaian**

**Status Saat Ini: ‚ùå BELUM OPTIMAL**

**Analisis:**

- **R¬≤ = 7.35%**: Model tidak menangkap pola preferensi
- **Poor high-rating detection**: Gagal identify buku berkualitas
- **Systematic bias**: Tidak memanfaatkan data rating secara optimal

**Solusi yang Diperlukan:**

- Redesign architecture untuk better pattern learning
- Implement hybrid approach (content + collaborative)
- Advanced feature engineering

***

## 8. Kesimpulan dan Rekomendasi

### **A. Status Evaluasi**

```javascript
üö® MODEL PERLU PERBAIKAN SIGNIFIKAN
‚ùå RMSE: 3.71 (Target: <2.0)
‚ùå R¬≤: 7.35% (Target: >70%)
‚ùå Akurasi ¬±2: 54% (Target: >80%)
```

### **B. Prioritas Perbaikan**

1. **Fix underprediction bias** - Ganti activation function
2. **Improve architecture** - Tambah complexity dan regularization  
3. **Balance training data** - Handle class imbalance
4. **Optimize hyperparameters** - Learning rate, embedding size, epochs

### **C. Expected Improvements**

Dengan perbaikan yang tepat, target performance:

- **RMSE**: 3.71 ‚Üí <2.0 (improvement 46%)
- **R¬≤**: 7.35% ‚Üí >70% (improvement 850%)
- **Akurasi ¬±2**: 54% ‚Üí >80% (improvement 48%)

### **D. Business Impact**

Setelah perbaikan, sistem akan dapat:

- ‚úÖ Memberikan rekomendasi akurat dan personal
- ‚úÖ Mengidentifikasi buku berkualitas tinggi
- ‚úÖ Mempercepat discovery proses untuk user
- ‚úÖ Meningkatkan user satisfaction dan engagement

**Status Final: Model memerlukan iterasi pengembangan sebelum deployment produksi.**
"""