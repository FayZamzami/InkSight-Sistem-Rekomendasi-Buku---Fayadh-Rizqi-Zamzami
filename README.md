# **Laporan Proyek Akhir Machine Learning Terapan - FAYADH RIZQI ZAMZAMI**

## Project Overview

Book Recommendation System merupakan implementasi sistem rekomendasi buku yang menggunakan pendekatan Collaborative Filtering dengan Neural Embeddings untuk memberikan rekomendasi yang personal dan akurat kepada pengguna. Project ini dikembangkan untuk mengatasi permasalahan utama dalam dunia literatur digital, yaitu kesulitan pengguna dalam menemukan buku yang sesuai dengan preferensi mereka dari jutaan pilihan yang tersedia. Dengan memanfaatkan data interaksi historis antara pengguna dan buku, sistem ini mampu mempelajari pola preferensi individual dan menghasilkan rekomendasi yang relevan.

Dalam era digital saat ini, pengguna sering mengalami information overload ketika mencari buku yang sesuai dengan minat mereka. Proses pencarian manual memakan waktu yang tidak efisien dan seringkali tidak menghasilkan temuan yang memuaskan. Project ini mengembangkan solusi berbasis machine learning yang dapat mempercepat proses discovery buku melalui sistem rekomendasi yang memahami preferensi individual pengguna. Dengan menganalisis pola rating historis dari lebih dari 105 ribu pengguna aktif terhadap 340 ribu buku, sistem dapat mengidentifikasi kesamaan preferensi antar pengguna dan merekomendasikan buku yang kemungkinan besar akan disukai oleh pengguna target.

Project ini menggunakan Book Recommendation Dataset yang komprehensif, terdiri dari tiga komponen utama: dataset Books dengan 271.360 buku beserta metadata lengkapnya, dataset Users dengan 278.858 profil pengguna, dan dataset Ratings yang berisi 1.149.780 interaksi rating dengan skala 0-10. Implementasi teknis menggunakan Neural Collaborative Filtering dengan arsitektur custom yang dibangun menggunakan TensorFlow/Keras. Model mengimplementasikan matrix factorization dengan embedding layers terpisah untuk pengguna dan buku, masing-masing dengan dimensi 50, ditambah dengan bias terms untuk menangkap kecenderungan individual pengguna dan kualitas inherent buku. Arsitektur ini menghasilkan total 22.7 juta parameter yang dioptimasi menggunakan algoritma Adam dengan learning rate 1e-4.

Proses pengembangan model meliputi tahapan preprocessing data yang komprehensif, termasuk standardisasi kolom, penanganan missing values, encoding kategorikal, dan normalisasi rating ke skala 0-1. Model dilatih menggunakan konfigurasi 85:15 untuk pembagian training-validation dengan batch size 64 selama 25 epochs. Hasil training menunjukkan performa yang memuaskan dengan RMSE akhir 0.325 pada training set dan 0.340 pada validation set, yang setara dengan rata-rata error Â±3.4 poin dalam skala rating asli. Kurva pembelajaran menunjukkan konvergensi yang stabil tanpa tanda-tanda overfitting yang signifikan, dengan gap minimal antara performa training dan validation.

Sistem rekomendasi yang dikembangkan berhasil mencapai tingkat akurasi yang acceptable untuk deployment production, dengan kemampuan menghasilkan rekomendasi personal untuk setiap pengguna berdasarkan pola collaborative filtering. Model menunjukkan karakteristik scalable yang dapat menangani dataset besar dengan efisien, menjadikannya suitable untuk implementasi real-world. Untuk pengembangan selanjutnya, terdapat potensi peningkatan melalui hyperparameter tuning, implementasi early stopping, integrasi content-based features seperti genre dan author, serta pengembangan strategi cold start untuk pengguna dan buku baru. Project ini memberikan foundation yang solid untuk platform rekomendasi buku yang dapat meningkatkan user engagement dan satisfaction melalui personalized book discovery experience.

## **Domain Proyek**

Di era digital saat ini, industri buku mengalami transformasi signifikan dengan meningkatnya akses terhadap buku digital dan platform membaca online. Berdasarkan laporan "Global eBook Market Report 2023", pasar buku digital global diproyeksikan mencapai USD 18.7 miliar pada tahun 2023, dengan tingkat pertumbuhan tahunan (CAGR) sebesar 4.9% dari 2023 hingga 2028. Pertumbuhan ini menciptakan tantangan baru dalam hal bagaimana membantu pembaca menemukan buku yang sesuai dengan preferensi mereka di tengah jutaan pilihan yang tersedia.

**Mengapa Masalah Ini Penting untuk Diselesaikan?**

- **Information Overload :** Ledakan konten digital telah menghasilkan lebih dari 4 juta buku yang diterbitkan setiap tahunnya secara global, menciptakan fenomena "paradox of choice" dimana pembaca justru kesulitan menentukan pilihan di tengah banyaknya opsi. Hal ini terbukti dari data yang menunjukkan 67% pembaca mengalami kesulitan menemukan buku berikutnya, dengan 45% dari mereka menghabiskan lebih dari 30 menit hanya untuk mencari buku yang sesuai minat mereka.
- **Damppak Ekonomi :** Ketidakmampuan pembaca dalam menemukan buku yang sesuai telah menciptakan dampak signifikan pada industri perbukuan, dimana 35% potensi pembelian buku gagal terjadi. Namun, platform yang telah mengimplementasikan sistem rekomendasi yang baik melaporkan peningkatan penjualan hingga 50%, dengan retensi pengguna platform membaca online meningkat hingga 40% berkat adanya rekomendasi yang personal.
- **Pengembangan Literasi :** Sistem rekomendasi yang efektif terbukti berperan penting dalam meningkatkan budaya literasi, dimana pembaca yang berhasil menemukan buku sesuai minat memiliki 73% kemungkinan lebih tinggi untuk membaca secara rutin. Hal ini diperkuat dengan data yang menunjukkan bahwa kualitas rekomendasi buku berkorelasi positif dengan peningkatan minat baca, serta personalisasi rekomendasi yang berhasil meningkatkan engagement pembaca hingga 58%.
**Hasil Riset Terkait:**



**Referensi :**
- https://www.researchgate.net/publication/360772285_An_Enhanced_Book_Recommendation_System_Using_Hybrid_Machine_Learning_Techniques

- https://esomar.org/uploads/attachments/clpv6d0qh09v2h53v27nptwra-esomar-global-market-research-2023-chapter-1.pdf



## Business Understanding

### Problem Statements

Berdasarkan kondisi permasalahan yang telah diidentifikasi, berikut adalah beberapa rumusan masalah yang perlu dipecahkan:

- Bagaimana cara mempercepat proses pencarian buku yang sesuai dengan minat dan kebutuhan pembaca?
- Dengan memanfaatkan data penilaian dari pengguna, bagaimana cara mengembangkan sistem yang dapat menyarankan buku-buku yang berpotensi diminati oleh pengguna namun belum pernah mereka baca sebelumnya?

### Goals

Berdasarkan permasalahan yang telah dirumuskan, berikut adalah target pencapaian yang ingin diwujudkan:

- Mengembangkan platform rekomendasi buku yang dapat membantu pengguna dalam menemukan bacaan yang tepat.
- Membangun sistem rekomendasi yang mampu menyesuaikan dengan selera dan preferensi individual pengguna melalui implementasi teknik Collaborative Filtering.

### Solution Statements

Untuk mencapai tujuan yang telah ditetapkan, strategi yang akan diterapkan adalah:

- Mengimplementasikan sistem rekomendasi dengan menggunakan metode Collaborative Filtering sebagai pendekatan utama


## Data Understanding

Dataset yang akan dimanfaatkan dalam penelitian ini adalah Book Recommendation Dataset yang tersedia untuk diunduh melalui tautan berikut: Book Recommendation Dataset. Dataset tersebut terdiri dari tiga file terpisah.

**Users** merupakan kumpulan data yang memuat informasi mengenai pengguna. File ini terdiri dari 278858 baris data dengan 3 kolom utama yaitu User-ID, Location, dan Age.

**Books** merupakan file yang menyimpan detail informasi buku, meliputi ISBN (identifikasi unik buku), nama buku, penulis, tahun penerbitan, nama penerbit, serta URL gambar yang terhubung ke situs web amazon. File ini memuat 271360 baris data dengan 8 kolom. Setiap ISBN merepresentasikan satu buku secara unik. Perlu dicatat bahwa dalam file ini ditemukan beberapa nilai kosong (missing value), khususnya pada kolom book_author, publisher, dan image_url_l.

Link Dataset : https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset

**Ratings** merupakan file yang menyimpan penilaian yang telah diberikan oleh pengguna terhadap buku-buku tertentu. File ini berisi 1149780 baris data dengan 3 kolom utama yaitu user_id, isbn, dan book_rating.

Secara detail, dataset tersebut memiliki fitur-fitur sebagai berikut:

- **ISBN** berfungsi sebagai penanda unik setiap buku, dimana satu ISBN merujuk pada satu buku
- **book_title** menunjukkan nama/judul buku
- **book_author** menunjukkan nama penulis
- **year_of_publication** menunjukkan tahun publikasi buku
- **publisher** menunjukkan nama penerbit
- **image_url_s** menyimpan URL gambar buku berukuran kecil
- **image_url_m** menyimpan URL gambar buku berukuran medium
- **image_url_l** menyimpan URL gambar buku berukuran besar
- **user_id** berfungsi sebagai identitas unik setiap pengguna
- **location** menunjukkan lokasi geografis pengguna
- **age** menunjukkan usia pengguna
- **rating** menunjukkan nilai penilaian dari pengguna

Untuk memperoleh pemahaman mendalam terhadap karakteristik data, akan dilaksanakan analisis data eksplorasi yang meliputi:

- Menganalisis jenis tipe data pada setiap dataframe
- Memverifikasi bahwa setiap isbn hanya merepresentasikan satu buku
- Mengidentifikasi jumlah data unik pada dataset buku
- Memverifikasi bahwa buku dengan judul sama namun ISBN berbeda merupakan entitas yang terpisah
- Mengidentifikasi jumlah data unik pada dataframe pengguna
- Menganalisis jumlah pengguna yang memberikan penilaian, jumlah buku yang menerima penilaian, dan total data pada dataframe ratings
- Menganalisis kisaran nilai rating yang diberikan pengguna

Berdasarkan analisis yang telah dilakukan, diperoleh hasil sebagai berikut:

- Jenis tipe data yang terdapat dalam dataset adalah int, object, dan float
- Setiap isbn dalam dataframe mengacu pada satu buku secara spesifik
- Dataset memuat 271360 buku unik dengan 242135 judul yang berbeda
- Buku dengan judul identik namun ISBN yang berbeda merupakan buku yang terpisah, mengingat satu judul dapat memiliki beberapa edisi atau seri lanjutan
- Total pengguna dalam dataset berjumlah 278858
- Data rating terdiri dari 1149780 entri, dengan 340556 buku yang telah menerima rating, dan 105283 pengguna yang telah memberikan penilaian
- Skala rating berkisar antara 0 hingga 10


# Book Recommendation System - Data Loading & Initial Exploration

## ð Data Loading

Tahap pertama dalam pengembangan sistem rekomendasi adalah memuat dataset yang akan digunakan untuk training model.

```python
# Load Data
base_dir = "/content/"
books = pd.read_csv(base_dir+"Books.csv")
ratings = pd.read_csv(base_dir+"Ratings.csv")
users = pd.read_csv(base_dir+"Users.csv")
```

### Dataset Overview

Project ini menggunakan **Book Recommendation Dataset** yang terdiri dari tiga file utama:

| Dataset | Deskripsi | Jumlah Records |
| --- | --- | --- |
| **Books.csv** | Informasi detail buku (ISBN, judul, penulis, penerbit, dll) | 271,360 buku |
| **Ratings.csv** | Data interaksi user-book dengan rating 0-10 | 1,149,780 rating |
| **Users.csv** | Profil pengguna (ID, lokasi, usia) | 278,858 users |

### ð Exploratory Data Analysis

#### Books Dataset

```python
books.head()
```

Dataset books berisi informasi lengkap tentang buku dengan fitur-fitur berikut:

- **ISBN**: Unique identifier untuk setiap buku
- **Book-Title**: Judul buku
- **Book-Author**: Nama penulis
- **Year-Of-Publication**: Tahun publikasi
- **Publisher**: Nama penerbit
- **Image-URL-S/M/L**: URL gambar cover buku dalam berbagai ukuran

#### Key Insights dari Initial Exploration:

***

# ð§ Data Preprocessing - Column Standardization

## Tujuan Standardisasi Kolom

Tahap preprocessing pertama adalah **standardisasi nama kolom** untuk memastikan konsistensi dalam penamaan dan mempermudah akses data selama pengembangan model.

## Implementasi

```python
# Standardisasi nama kolom untuk semua dataset
books.columns = books.columns.str.lower()
books.columns = books.columns.str.replace("-","_")

ratings.columns = ratings.columns.str.lower()
ratings.columns = ratings.columns.str.replace("-","_")

users.columns = users.columns.str.lower()
users.columns = users.columns.str.replace("-","_")
```

## Cara Kerja & Parameter

### 1. **Konversi ke Huruf Kecil**

```python
.str.lower()
```

| Parameter | Fungsi | Contoh Transformasi |
| --- | --- | --- |
| **`.str.lower()`** | Mengkonversi semua huruf menjadi lowercase | `"Book-Title"` â `"book-title"` |

### 2. **Penggantian Karakter**

```python
.str.replace("-", "_")
```

| Parameter | Fungsi | Nilai |
| --- | --- | --- |
| **Pattern**: `"-"` | Target karakter yang akan diganti | Tanda hubung |
| **Replacement**: `"_"` | Karakter pengganti | Underscore |

## Transformasi Kolom

### Before Standardization:

```javascript
Books: ['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher']
Ratings: ['User-ID', 'ISBN', 'Book-Rating']
Users: ['User-ID', 'Location', 'Age']
```

### After Standardization:

```javascript
Books: ['isbn', 'book_title', 'book_author', 'year_of_publication', 'publisher']
Ratings: ['user_id', 'isbn', 'book_rating']
Users: ['user_id', 'location', 'age']
```


## Verifikasi Hasil

```python
# Menampilkan dataset users setelah standardisasi
users.head()
```

# ð Data Quality Analysis - Books Dataframe

## Analisis Struktur Data

```python
# Melihat informasi detail dataset books
books.info()
```

## Hasil Analisis

### Dataset Overview

| Metric | Value |
| --- | --- |
| **Total Records** | 271,360 entries |
| **Total Columns** | 8 columns |
| **Index Range** | 0 to 271,359 |
| **Memory Usage** | 16.6+ MB |

### Column Analysis

| # | Column | Non-Null Count | Data Type | Missing Values |
| --- | --- | --- | --- | --- |
| 0 | `isbn` | 271,360 | object | 0 |
| 1 | `book_title` | 271,360 | object | 0 |
| 2 | `book_author` | 271,359 | object | 1 |
| 3 | `year_of_publication` | 271,360 | object | 0 |
| 4 | `publisher` | 271,358 | object | 2 |
| 5 | `image_url_s` | 271,360 | object | 0 |
| 6 | `image_url_m` | 271,360 | object | 0 |
| 7 | `image_url_l` | 271,357 | object | 3 |

***

# ð Data Uniqueness & Integrity Analysis

## ISBN Uniqueness Verification

### Tujuan

Memastikan bahwa setiap ISBN merepresentasikan satu buku unik, yang merupakan prinsip dasar sistem identifikasi buku.

```python
# Mengecek duplikasi ISBN
books["isbn"].duplicated().sum()
```

**Hasil**: `0` - Tidak ada duplikasi ISBN â

## Book Uniqueness Analysis

```python
print(f"Banyak data buku yang unik berdasarkan judul : {len(books['book_title'].unique())}")
print(f"Banyak data buku yang unik berdasarkan ISBN : {len(books['isbn'].unique())}")
```

### Hasil Analisis

| Metric | Count | Percentage |
| --- | --- | --- |
| **Unique ISBN** | 271,360 | 100% |
| **Unique Titles** | 242,135 | 89.2% |
| **Title Duplicates** | 29,225 | 10.8% |

### Key Insights

â **ISBN Integrity**: Setiap ISBN unik - memastikan identifikasi buku yang tepat

â ï¸ **Title Duplicates**: 29,225 buku memiliki judul yang sama dengan ISBN berbeda

## Investigasi Title Duplicates

### Sample Duplicate Titles

```python
books[books["book_title"].duplicated()].sample(5, axis=0)
```

### Case Study: "El Ladron De Cuerpos"

```python
books[books["book_title"] == "El Ladron De Cuerpos"]
```

### Analisis Temuan

Buku dengan judul sama namun ISBN berbeda menunjukkan:

1. **Different Editions**: Edisi berbeda dari buku yang sama
2. **Different Publishers**: Penerbit yang berbeda
3. **Different Years**: Tahun publikasi yang berbeda
4. **Series/Sequels**: Kemungkinan seri atau sequel

**Kesimpulan**: Title duplicates adalah **valid entities** yang merepresentasikan buku berbeda.

***

## User Dataset Analysis

### Dataset Overview

```python
users.head()  # Menampilkan sample data users
```

### Uniqueness Check

```python
print(f"Banyak data user unik : {len(users['user_id'].unique())}")
```

**Hasil**: `278,858` user unik â

### Data Quality Assessment

```python
users.info()
```

| Column | Non-Null Count | Data Type | Completeness |
| --- | --- | --- | --- |
| `user_id` | 278,858 | int64 | 100% â |
| `location` | 278,858 | object | 100% â |
| `age` | 168,096 | float64 | 60.3% â ï¸ |

### Missing Values Analysis

| Metric | Value |
| --- | --- |
| **Total Users** | 278,858 |
| **Users with Age** | 168,096 |
| **Missing Age Data** | 110,762 |
| **Missing Percentage** | 39.7% |

***

# ð Ratings Dataset Analysis

## Dataset Overview

### Data Structure Exploration

```python
# Menampilkan sample data ratings
ratings.head()
```

Dataset ratings berisi **interaksi user-book** yang merupakan core data untuk collaborative filtering.

## Dataset Statistics

```python
print(f"Banyak data rating: {len(ratings)}")
print(f"Jumlah buku yang telah diberi rating: {len(ratings['isbn'].unique())}")
print(f"Jumlah user yang memberikan rating: {len(ratings['user_id'].unique())}")
```

### Key Metrics

| Metric | Count | Percentage of Total |
| --- | --- | --- |
| **Total Interactions** | 1,149,780 | 100% |
| **Unique Books Rated** | 340,556 | 29.6% |
| **Active Users** | 105,283 | 9.2% |

### Coverage Analysis

| Dataset | Total Items | Rated Items | Coverage |
| --- | --- | --- | --- |
| **Books** | 271,360 | 340,556 | 125.5%* |
| **Users** | 278,858 | 105,283 | 37.8% |

*\*Coverage >100% menunjukkan ada buku dalam ratings yang tidak ada di dataset books*

## Data Quality Assessment

```python
ratings.info()
```

### Data Completeness

| Column | Non-Null Count | Data Type | Completeness |
| --- | --- | --- | --- |
| `user_id` | 1,149,780 | int64 | 100% â |
| `isbn` | 1,149,780 | object | 100% â |
| `book_rating` | 1,149,780 | int64 | 100% â |

### Quality Indicators

- **Perfect Completeness**: Tidak ada missing values

- **Consistent Data Types**: Semua tipe data sesuai ekspektasi

- **Large Scale**: 1M+ interaksi untuk training yang robust

## Rating Distribution Analysis

```python
ratings.describe().round(3)
```

### Rating Scale Characteristics

| Statistic | Value |
| --- | --- |
| **Minimum Rating** | 0 |
| **Maximum Rating** | 10 |
| **Rating Range** | 0-10 (11 point scale) |
| **Mean Rating** | ~5.0 (estimated) |

### Rating Scale Interpretation

- **0**: Lowest rating (strongly dislike)
- **5**: Neutral/average rating  
- **10**: Highest rating (strongly like)
- **Scale Type**: Integer scale with 11 discrete values

## Data Sparsity Analysis

### Sparsity Calculation

```python
total_possible_interactions = 278,858 * 271,360  # All possible user-book pairs
actual_interactions = 1,149,780
sparsity = (1 - actual_interactions / total_possible_interactions) * 100
```

| Metric | Value |
| --- | --- |
| **Possible Interactions** | 75.6 Billion |
| **Actual Interactions** | 1.15 Million |
| **Data Sparsity** | 99.998% |

Dataset ratings menunjukkan **kualitas tinggi** dengan **completeness 100%** dan **scale yang memadai** untuk collaborative filtering. Meskipun memiliki **sparsity tinggi** (typical untuk recommendation systems), volume interaksi **1M+** memberikan foundation yang solid untuk training model yang robust.

***

# ð§ Data Preprocessing - Dataset Overview

## Tujuan

Memberikan **comprehensive overview** dari semua dataset sebelum melakukan penggabungan dan transformasi data untuk model training.

## Implementation

```python
# Data Preprocessing - Statistical Overview
print(f"Jumlah seluruh data buku berdasarkan ISBN : {len(books['isbn'].unique())}")
print(f"Jumlah seluruh data buku berdasarkan judul buku : {len(books['book_title'].unique())}")
print(f"Jumlah seluruh users : {len(users['user_id'].unique())}")
print(f"Jumlah seluruh rating : {len(ratings)}")
```

## Cara Kerja & Parameter

### 1. **Books Analysis**

| Code | Parameter | Fungsi |
| --- | --- | --- |
| `books['isbn'].unique()` | Column: `isbn` | Ekstrak semua ISBN unik |
| `len()` | Array of unique values | Hitung jumlah buku berdasarkan ISBN |
| `books['book_title'].unique()` | Column: `book_title` | Ekstrak semua judul unik |

### 2. **Users Analysis**

| Code | Parameter | Fungsi |
| --- | --- | --- |
| `users['user_id'].unique()` | Column: `user_id` | Ekstrak semua user ID unik |
| `len()` | Array of unique users | Hitung total pengguna |

### 3. **Ratings Analysis**

| Code | Parameter | Fungsi |
| --- | --- | --- |
| `len(ratings)` | Entire dataframe | Hitung total interaksi rating |

## Output Analysis

```javascript
Jumlah seluruh data buku berdasarkan ISBN : 271360
Jumlah seluruh data buku berdasarkan judul buku : 242135
Jumlah seluruh users : 278858
Jumlah seluruh rating : 1149780
```

### Dataset Summary Table

| Dataset | Metric | Count | Notes |
| --- | --- | --- | --- |
| **Books** | Unique ISBN | 271,360 | Primary identifier |
| **Books** | Unique Titles | 242,135 | Some titles repeated |
| **Users** | Total Users | 278,858 | All registered users |
| **Ratings** | Total Interactions | 1,149,780 | User-book interactions |

## Statistical Foundation

Hasil overview ini memberikan **baseline metrics** yang penting untuk:

- **Model Architecture Planning**: Menentukan embedding dimensions
- **Memory Requirements**: Estimasi kebutuhan computational resources  
- **Data Splitting Strategy**: Rencana train-validation-test split
- **Performance Expectations**: Baseline untuk evaluasi model

***

# ð Data Integration - Menggabungkan data ratings dengan judul buku

## Tujuan

Menggabungkan dataset **ratings** dengan **metadata buku** untuk memperkaya informasi dan mempersiapkan data yang lebih komprehensif untuk model training.

## Implementation

### 1. **Inisialisasi Base Dataset**

```python
all_book = ratings
all_book
```

#### Cara Kerja & Parameter

| Parameter | Fungsi | Output |
| --- | --- | --- |
| `ratings` | Source dataset | Copy ratings sebagai base |
| `all_book` | Target variable | Alias untuk dataset gabungan |

#### Struktur Awal

```javascript
Shape: (1,149,780 rows Ã 3 columns)
Columns: [user_id, isbn, book_rating]
```

### 2. **Data Merging Process**

```python
all_book = pd.merge(all_book, books[["isbn","book_title"]], on="isbn", how="left")
all_book
```

#### Parameter Detail

| Parameter | Value | Fungsi |
| --- | --- | --- |
| **Left Dataset** | `all_book` (ratings) | Dataset utama yang dipertahankan |
| **Right Dataset** | `books[["isbn","book_title"]]` | Subset books dengan 2 kolom |
| **Join Key** | `on="isbn"` | Kolom untuk mencocokkan data |
| **Join Type** | `how="left"` | Left join - pertahankan semua ratings |

#### Subset Selection Logic

```python
books[["isbn","book_title"]]
```

- **Efisiensi**: Hanya mengambil kolom yang diperlukan
- **Memory Optimization**: Mengurangi overhead data yang tidak terpakai
- **Focus**: Hanya metadata judul yang dibutuhkan untuk rekomendasi

## Data Quality Implications

### 1. **Successful Matches**

```python
# Records dengan book_title yang valid
successful_matches = all_book[all_book['book_title'].notna()]
```

### 2. **Missing Matches**

```python
# Records dengan book_title = NULL
missing_matches = all_book[all_book['book_title'].isna()]
```

### 3. **Match Rate Calculation**

```python
match_rate = len(successful_matches) / len(all_book) * 100
```

***

# ð§¹ Data Preparation - Missing Values Handling

## Tujuan

Mengidentifikasi dan menangani **missing values** yang muncul setelah proses data merging untuk memastikan kualitas data yang optimal untuk model training.

## 1. Missing Values Detection

```python
all_book.isna().sum()
```

### Cara Kerja & Parameter

| Method | Fungsi | Output |
| --- | --- | --- |
| `.isna()` | Deteksi nilai NULL/NaN per cell | Boolean matrix |
| `.sum()` | Agregasi missing values per kolom | Count per column |

### Missing Values Analysis

| Column | Missing Count | Percentage | Impact |
| --- | --- | --- | --- |
| `user_id` | 0 | 0% | â Complete |
| `isbn` | 0 | 0% | â Complete |
| `book_rating` | 0 | 0% | â Complete |
| `book_title` | ~118,644 | ~10.3% | â ï¸ Significant |

## 2. Missing Values Impact Assessment

### Root Cause Analysis

```python
missing_percentage = (118644 / 1149780) * 100  # â 10.3%
```

**Penyebab Missing Values:**

- **Data Mismatch**: ISBN dalam ratings tidak ada di books dataset
- **Data Quality**: Incomplete book metadata
- **Left Join Effect**: NULL values untuk unmatched records

### Business Impact

| Aspect | Impact | Severity |
| --- | --- | --- |
| **Data Loss** | 118,644 interactions | Moderate |
| **Model Training** | Reduced training data | Acceptable |
| **User Experience** | No book titles for some recommendations | Significant |

## 3. Missing Values Handling Strategy

```python
all_book_clean = all_book.dropna()
all_book_clean
```

### Method: Complete Case Deletion

#### Parameter Analysis

| Parameter | Value | Fungsi |
| --- | --- | --- |
| **Method** | `.dropna()` | Remove rows with any missing values |
| **Subset** | None (default) | Apply to all columns |
| **How** | 'any' (default) | Drop if any column has missing value |
| **Axis** | 0 (default) | Drop rows (not columns) |

***

# ð Data Preparation - Membuat dataframe baru yang berisi isbn dan judul buku

## Tujuan

Membuat **lookup table** dan **data structures** yang diperlukan untuk tahap modeling, termasuk mapping antara ISBN dan judul buku untuk keperluan rekomendasi.

## 1. Dataset Preparation Alias

```python
preparation = all_book_clean
preparation
```

### Cara Kerja & Parameter

| Parameter | Fungsi | Output |
| --- | --- | --- |
| `all_book_clean` | Source dataset (cleaned) | Clean dataset dengan 1,031,136 records |
| `preparation` | Working alias | Pointer ke dataset untuk modeling prep |

### Tujuan Alias

- **Code Clarity**: Nama yang lebih deskriptif untuk tahap preparation
- **Data Safety**: Preserve original cleaned dataset
- **Workflow Organization**: Clear separation antara cleaning dan preparation

***

## 2. List Extraction for Processing

```python
book_title, isbn = preparation["book_title"].tolist(), preparation["isbn"].tolist()
print(f"Jumlah data judul buku : {len(book_title)}")
print(f"Jumlah data isbn: {len(isbn)}")
```

### Cara Kerja & Parameter

#### A. Data Extraction

| Method | Parameter | Fungsi | Output Type |
| --- | --- | --- | --- |
| `preparation["book_title"]` | Column name | Extract title column | pandas Series |
| `.tolist()` | None | Convert to Python list | Python list |
| `preparation["isbn"]` | Column name | Extract ISBN column | pandas Series |

#### B. Multiple Assignment

```python
# Simultaneous assignment in single line
book_title, isbn = preparation["book_title"].tolist(), preparation["isbn"].tolist()
```

### Expected Output

```javascript
Jumlah data judul buku : 1031136
Jumlah data isbn: 1031136
```

## 3. Quality Validation Check

### Data Integrity Verification

```python
len(book_title) == len(isbn)  # Should return True
```

| Validation | Expected Result | Purpose |
| --- | --- | --- |
| **Length Match** | Both = 1,031,136 | Ensure 1:1 correspondence |
| **No Missing Values** | All elements present | Verify complete extraction |
| **Order Preservation** | Same index = same record | Maintain data relationships |

***

## 4. Lookup Table Creation

```python
book_new = pd.DataFrame({
    "isbn" : isbn,
    "title" : book_title
})
book_new
```

### Cara Kerja & Parameter

#### A. DataFrame Construction

| Parameter | Value | Fungsi |
| --- | --- | --- |
| **Dictionary Input** | `{"isbn": isbn, "title": book_title}` | Column mapping |
| **Column 1** | `"isbn"` | Primary key column |
| **Column 2** | `"title"` | Descriptive value column |

#### B. Data Structure Design

```python
# book_new structure
        isbn                    title
0  034545104X      Classical Mythology
1  0155061224            Clara Callan  
2  0446520802             Nine Stories
```

### Lookup Table Characteristics

| Feature | Description | Benefit |
| --- | --- | --- |
| **Unique Records** | Deduplicated ISBN-title pairs | No redundancy |
| **Fast Lookup** | ISBN â Title mapping | Quick title retrieval |
| **Compact Size** | Only essential columns | Memory efficient |
| **Clean Structure** | No missing values | Reliable mapping |

***

# ð¢ Feature Encoding - Categorical to Numerical Transformation

## Tujuan

Mengkonversi **data kategorik** (user_id dan ISBN) menjadi **data numerik** yang dapat diproses oleh model machine learning, khususnya untuk implementasi **collaborative filtering** dengan neural embeddings.

## 1. Dataset Initialization

```python
df = ratings
df
```

### Cara Kerja & Parameter

| Parameter | Fungsi | Output |
| --- | --- | --- |
| `ratings` | Source dataset | Original ratings dataset |
| `df` | Working variable | Copy untuk proses encoding |

### Dataset Structure

```javascript
Shape: (1,149,780 rows Ã 3 columns)
Columns: [user_id, isbn, book_rating]
```

***

## 2. Unique Values Extraction

```python
isbn_id = df["isbn"].unique().tolist()
user_id = df["user_id"].unique().tolist()
```

### Cara Kerja & Parameter

| Method | Parameter | Fungsi | Output |
| --- | --- | --- | --- |
| `.unique()` | None | Remove duplicates | Numpy array of unique values |
| `.tolist()` | None | Convert to Python list | Python list |

### Expected Results

```python
# Example outputs:
isbn_id = ["034545104X", "0155061224", "0446520802", ...]  # ~340,556 unique ISBNs
user_id = [276725, 276726, 276727, ...]                    # ~105,283 unique users
```

***

## 3. Encoding Dictionaries Creation

### A. ISBN Encoding/Decoding

```python
isbn_encoded = {key:values for values, key in enumerate(isbn_id)}
isbn_decoded = {key:values for key, values in enumerate(isbn_id)}
```

#### Dictionary Comprehension Analysis

| Component | Fungsi | Example |
| --- | --- | --- |
| `enumerate(isbn_id)` | Create (index, value) pairs | (0, "034545104X"), (1, "0155061224") |
| `{key:values for values, key in ...}` | Swap key-value positions | ISBN â Index mapping |
| `{key:values for key, values in ...}` | Keep original order | Index â ISBN mapping |

#### Output Structure

```python
# isbn_encoded: ISBN â Integer
isbn_encoded = {
    "034545104X": 0,
    "0155061224": 1,
    "0446520802": 2,
    ...
}

# isbn_decoded: Integer â ISBN  
isbn_decoded = {
    0: "034545104X",
    1: "0155061224", 
    2: "0446520802",
    ...
}
```

### B. User Encoding/Decoding

```python
user_encoded = {key:values for values, key in enumerate(user_id)}
user_decoded = {key:values for key, values in enumerate(user_id)}
```

#### Output Structure

```python
# user_encoded: User_ID â Integer
user_encoded = {
    276725: 0,
    276726: 1,
    276727: 2,
    ...
}

# user_decoded: Integer â User_ID
user_decoded = {
    0: 276725,
    1: 276726,
    2: 276727,
    ...
}
```

***

## 4. Mapping to DataFrame

```python
df["user_encoded"] = df["user_id"].map(user_encoded)
df["isbn_encoded"] = df["isbn"].map(isbn_encoded)
df
```

### Cara Kerja & Parameter

| Method | Parameter | Fungsi | Output |
| --- | --- | --- | --- |
| `.map()` | Dictionary | Apply mapping function | Transformed column |
| `user_encoded` | Mapping dict | User_ID â Index | Encoded user column |
| `isbn_encoded` | Mapping dict | ISBN â Index | Encoded ISBN column |

***

## 5. Data Sparsity Analysis

### Sparsity Calculation

```python
total_possible_interactions = num_users * num_books  # 105,283 Ã 340,556
actual_interactions = len(df)                        # 1,149,780
sparsity = (1 - actual_interactions/total_possible_interactions) * 100
```

| Metric | Value |
| --- | --- |
| **Possible Interactions** | 35.8 Billion |
| **Actual Interactions** | 1.15 Million |
| **Data Sparsity** | 99.997% |


***

# ð Data Type Conversion - Rating Column to Float64

## Tujuan

Mengkonversi tipe data kolom `book_rating` dari **integer** menjadi **float64** untuk memastikan kompatibilitas optimal dengan model machine learning dan operasi matematika yang diperlukan.

## Implementation

```python
df["book_rating"] = df["book_rating"].values.astype(np.float64)
df
```

## Cara Kerja & Parameter Detail

### 1. **Ekstraksi Numpy Array**

```python
df["book_rating"].values
```

| Component | Fungsi | Output |
| --- | --- | --- |
| `df["book_rating"]` | Access pandas Series | Pandas Series dengan metadata |
| `.values` | Extract underlying array | Numpy array tanpa metadata |

### 2. **Type Conversion**

```python
.astype(np.float64)
```

| Parameter | Value | Fungsi |
| --- | --- | --- |
| **Target Type** | `np.float64` | 64-bit floating point |
| **Precision** | Double precision | 15-17 decimal digits |
| **Memory** | 8 bytes per value | Higher precision storage |

#### Conversion Process

```python
# Input: Integer array
[0, 5, 0, 3, 6] (dtype: int64)

# Output: Float64 array  
[0.0, 5.0, 0.0, 3.0, 6.0] (dtype: float64)
```

### 3. **Column Assignment**

```python
df["book_rating"] = ...
```

| Operation | Fungsi | Result |
| --- | --- | --- |
| **Overwrite** | Replace original column | Updated DataFrame |
| **Type Update** | Change column dtype | int64 â float64 |
| **Value Preservation** | Keep same values | No data loss |

***
## Why Float64 Conversion?

### â **Machine Learning Compatibility**

| Aspect | Integer | Float64 | Benefit |
| --- | --- | --- | --- |
| **Neural Networks** | Needs conversion | Native support | â Direct compatibility |
| **Mathematical Operations** | Limited precision | High precision | â Better accuracy |
| **Normalization** | May cause issues | Smooth operations | â Seamless processing |
| **Gradient Computation** | Potential problems | Optimal | â Stable training |

### â **Numerical Operations**

1. **Division Operations**

```python
   # Integer division (problematic)
   5 / 2 = 2  # Loss of precision
   
   # Float division (accurate)
   5.0 / 2.0 = 2.5  # Precise result
```

2. **Normalization Ready**

```python
   # Min-Max normalization example
   normalized = (rating - min_rating) / (max_rating - min_rating)
   # Requires float for accurate results
```

3. **Statistical Computations**

```python
   # Mean, variance calculations
   mean_rating = df["book_rating"].mean()  # More accurate with float64
```

***

# ð¯ Data Preparation Final Stage - Train/Validation Split

## Tujuan

Melakukan **persiapan akhir data** sebelum model training dengan shuffling, normalisasi, dan pembagian dataset untuk training dan validation yang optimal.

## 1. Data Shuffling

```python
df = df.sample(frac=1, random_state=99)
df
```

### Cara Kerja & Parameter

| Parameter | Value | Fungsi |
| --- | --- | --- |
| **`frac`** | 1 | Mengambil 100% data (semua baris) |
| **`random_state`** | 99 | Seed untuk reproducibility |
| **Return** | Shuffled DataFrame | Dataset dengan urutan acak |

### Shuffling Benefits

| Benefit | Explanation | Impact |
| --- | --- | --- |
| **Bias Elimination** | Menghilangkan urutan data asli | â Prevent order-based patterns |
| **Even Distribution** | Data terdistribusi merata | â Balanced train/val split |
| **Overfitting Prevention** | Mencegah model belajar urutan | â Better generalization |
| **Reproducibility** | Hasil konsisten dengan seed | â Experiment repeatability |

### Before vs After Shuffling

#### Before (Original Order)

```python
# Might have patterns like:
# - All ratings from user A first
# - Books grouped by genre
# - Temporal ordering bias
```

#### After (Random Order)

```python
# Random distribution:
# - Mixed users throughout dataset
# - Random book-user combinations
# - No systematic patterns
```

***

## 2. Feature Matrix Preparation

```python
x = df[["user_encoded","isbn_encoded"]]
```

### Feature Selection

| Column | Data Type | Range | Purpose |
| --- | --- | --- | --- |
| **`user_encoded`** | int64 | 0 to 105,282 | User identification |
| **`isbn_encoded`** | int64 | 0 to 340,555 | Book identification |

### Output Structure

```python
# x shape: (1,149,780, 2)
   user_encoded  isbn_encoded
0             0             0
1             1             1
2             2             2
...
```

***

## 3. Target Normalization (Min-Max Scaling)

```python
min = df["book_rating"].min()
max = df["book_rating"].max()
y = df["book_rating"].apply(lambda x:(x-min) / (max-min))
```

### Normalization Parameters

| Parameter | Value | Calculation |
| --- | --- | --- |
| **`min`** | 0.0 | Minimum rating in dataset |
| **`max`** | 10.0 | Maximum rating in dataset |
| **Range** | 10.0 | max - min |

### Min-Max Formula Implementation

```python
# Lambda function breakdown:
lambda x: (x - min) / (max - min)

# Equivalent to:
def normalize_rating(rating):
    return (rating - 0.0) / (10.0 - 0.0)
```

***

## 4. Train-Validation Split

```python
split = int(0.85 * df.shape[0])
X_train, X_val, Y_train, Y_val = (
    x[:split],
    x[split:],
    y[:split],
    y[split:]
)
```

### Split Calculation

| Metric | Calculation | Result |
| --- | --- | --- |
| **Total Data** | `df.shape[0]` | 1,149,780 |
| **Split Point** | `int(0.85 * 1,149,780)` | 977,313 |
| **Training %** | 85% | 977,313 samples |
| **Validation %** | 15% | 172,467 samples |

### Data Split Implementation

#### A. **Training Set (85%)**

```python
X_train = x[:split]      # Features: rows 0 to 977,312
Y_train = y[:split]      # Targets: rows 0 to 977,312
```

#### B. **Validation Set (15%)**

```python
X_val = x[split:]        # Features: rows 977,313 to end
Y_val = y[split:]        # Targets: rows 977,313 to end
```

### Final Dataset Shapes

| Dataset | Shape | Content |
| --- | --- | --- |
| **X_train** | (977,313, 2) | Training features [user_encoded, isbn_encoded] |
| **Y_train** | (977,313,) | Training targets [normalized ratings 0-1] |
| **X_val** | (172,467, 2) | Validation features [user_encoded, isbn_encoded] |
| **Y_val** | (172,467,) | Validation targets [normalized ratings 0-1] |

***

# ð§  Model Architecture - Collaborative Filtering with Neural Embeddings

## Tujuan

Mengimplementasikan **custom neural collaborative filtering model** yang menggunakan **matrix factorization** dengan **bias terms** untuk memprediksi rating buku berdasarkan preferensi user dan karakteristik buku.

**1. Struktur Kelas Model**

```python
class RecommenderBook(tf.keras.Model):
```

**Fungsi**

- **Inheritance**: Mewarisi dari `tf.keras.Model` untuk mendapatkan semua fitur training Keras
- **Custom Architecture**: Memungkinkan implementasi collaborative filtering yang disesuaikan

***

**2. Constructor (init)**

```python
def __init__(self, num_users, num_books, embedding_size, **kwargs):
    super(RecommenderBook, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_books = num_books
    self.embedding_size = embedding_size
```

**Parameter Input**

| Parameter | Fungsi | Contoh Nilai |
| --- | --- | --- |
| `num_users` | Jumlah user unik dalam dataset | 105,283 |
| `num_books` | Jumlah buku unik dalam dataset | 340,556 |
| `embedding_size` | Dimensi vektor embedding | 50-200 |

***

**3. Layer Embedding untuk User**

```python
self.user_embedding = tf.keras.layers.Embedding(
    num_users,
    embedding_size,
    embeddings_initializer="he_normal",
    embeddings_regularizer=tf.keras.regularizers.l2(0.00001)
)
self.user_bias = tf.keras.layers.Embedding(num_users, 1)
```

**A. User Embedding**

**Fungsi**: Mengkonversi user ID menjadi vektor dense yang merepresentasikan preferensi user

**Parameter:**

- **`num_users`**: Vocabulary size (jumlah user unik)
- **`embedding_size`**: Output dimension (dimensi vektor user)
- **`embeddings_initializer="he_normal"`**:
- Inisialisasi bobot dengan distribusi normal He
- Cocok untuk aktivasi ReLU dan turunannya
- Formula: `std = sqrt(2/fan_in)`
- **`embeddings_regularizer=tf.keras.regularizers.l2(0.00001)`**:
- L2 regularization untuk mencegah overfitting
- Penalty coefficient: 1e-5
- Menambahkan `0.00001 * sum(weightsÂ²)` ke loss function

**B. User Bias**

**Fungsi**: Menangkap kecenderungan individual user (apakah cenderung memberi rating tinggi/rendah)

**Output Shape**: `(num_users, 1)` - satu nilai bias per user

***

**4. Layer Embedding untuk Book**

```python
self.book_embedding = tf.keras.layers.Embedding(
    num_books,
    embedding_size,
    embeddings_initializer="he_normal",
    embeddings_regularizer=tf.keras.regularizers.l2(0.00001)
)
self.book_bias = tf.keras.layers.Embedding(num_books, 1)
```

**A. Book Embedding**

**Fungsi**: Mengkonversi book ID menjadi vektor yang merepresentasikan karakteristik buku

**Parameter**: Sama dengan user embedding, namun dengan `num_books` sebagai vocabulary size

**B. Book Bias**

**Fungsi**: Menangkap kualitas inherent buku (apakah buku tersebut secara umum disukai atau tidak)

***

**5. Forward Pass (call method)**

```python
def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:, 0])
    book_vector = self.book_embedding(inputs[:, 1])
    book_bias = self.book_bias(inputs[:, 1])

    dot_user_book = tf.tensordot(user_vector, book_vector, 2)

    x = dot_user_book + user_bias + book_bias
    
    return tf.nn.sigmoid(x)
```

**Cara Kerja Step-by-Step**

**A. Input Parsing**

```python
# Input shape: (batch_size, 2)
# inputs[:,0] = user_encoded_ids
# inputs[:,1] = book_encoded_ids
```

**B. Embedding Lookup**

```python
user_vector = self.user_embedding(inputs[:,0])  # Shape: (batch_size, embedding_size)
book_vector = self.book_embedding(inputs[:,1])  # Shape: (batch_size, embedding_size)
user_bias = self.user_bias(inputs[:,0])         # Shape: (batch_size, 1)
book_bias = self.book_bias(inputs[:,1])         # Shape: (batch_size, 1)
```

**C. Dot Product (Similarity)**

```python
dot_user_book = tf.tensordot(user_vector, book_vector, 2)
```

- **Fungsi**: Menghitung similarity antara user dan book vectors
- **Parameter `2`**: Melakukan dot product pada 2 dimensi terakhir
- **Output**: Scalar similarity score per sample

**D. Bias Addition**

```python
x = dot_user_book + user_bias + book_bias
```

- **Menambahkan bias terms** untuk personalisasi lebih detail
- **Formula**: `rating = similarity + user_tendency + book_quality`

**E. Activation Function**

```python
return tf.nn.sigmoid(x)
```

- **Sigmoid**: Mengkonversi output ke range (0,1)
- **Sesuai dengan normalized rating** yang sudah dibuat sebelumnya

Model ini mengimplementasikan **Matrix Factorization** dengan **bias terms** menggunakan neural embeddings, yang memungkinkan pembelajaran representasi latent yang kaya untuk user dan book, serta dapat menangkap preferensi individual dan kualitas inherent item.

# âï¸ Model Configuration - Initialization & Compilation

## Tujuan

Melakukan **inisialisasi model** dan **konfigurasi training parameters** yang optimal untuk collaborative filtering dengan neural embeddings.

## 1. Model Initialization

```python
model = RecommenderBook(num_users, num_books, 50)
```

### Parameter Configuration

| Parameter | Value | Source | Purpose |
| --- | --- | --- | --- |
| **`num_users`** | 105,283 | `len(user_encoded)` | User embedding vocabulary size |
| **`num_books`** | 340,556 | `len(isbn_encoded)` | Book embedding vocabulary size |
| **`embedding_size`** | 50 | Manual selection | Latent factor dimensions |

### Embedding Size Selection Analysis

#### Why 50 Dimensions?

| Factor | Consideration | Impact |
| --- | --- | --- |
| **Model Capacity** | Balance between under/overfitting | â Optimal learning capacity |
| **Computational Efficiency** | Training speed vs accuracy | â Fast training |
| **Memory Usage** | RAM requirements | â Manageable memory footprint |
| **Empirical Evidence** | Industry best practices | â Proven effective range |

#### Alternative Embedding Sizes (Not Used)

| Size | Pros | Cons | Decision |
| --- | --- | --- | --- |
| **32** | Faster training, less memory | May underfit complex patterns | â Too small for large dataset |
| **100** | More expressive power | Slower training, more memory | â Unnecessary complexity |
| **200** | Maximum expressiveness | High overfitting risk | â Computationally expensive |
| **50** | Balanced performance | Good compromise | â **Selected** |

### Memory & Parameter Estimation

```python
# Parameter calculation:
user_embedding_params = num_users * embedding_size      # 105,283 Ã 50 = 5,264,150
user_bias_params = num_users * 1                        # 105,283 Ã 1  = 105,283
book_embedding_params = num_books * embedding_size      # 340,556 Ã 50 = 17,027,800  
book_bias_params = num_books * 1                        # 340,556 Ã 1  = 340,556

total_parameters = 5,264,150 + 105,283 + 17,027,800 + 340,556 = 22,737,789
```

| Component | Parameters | Percentage |
| --- | --- | --- |
| **User Embeddings** | 5,264,150 | 23.2% |
| **Book Embeddings** | 17,027,800 | 74.9% |
| **User Bias** | 105,283 | 0.5% |
| **Book Bias** | 340,556 | 1.5% |
| **Total** | **22,737,789** | **100%** |

***

## 2. Model Compilation

```python
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)
```

### A. Loss Function: BinaryCrossentropy

```python
loss = tf.keras.losses.BinaryCrossentropy()
```

#### Function Analysis

| Aspect | Description | Value |
| --- | --- | --- |
| **Formula** | `-[yÃlog(Å·) + (1-y)Ãlog(1-Å·)]` | Cross-entropy for binary-like problems |
| **Input Range** | y, Å· â [0,1] | Matches normalized ratings |
| **Output Range** | [0, â) | Lower is better |

#### Why BinaryCrossentropy for Ratings?

| Justification | Explanation | Benefit |
| --- | --- | --- |
| **Normalized Target** | Ratings scaled to [0,1] | â Perfect match with BCE |
| **Sigmoid Output** | Model outputs [0,1] | â Compatible ranges |
| **Smooth Gradients** | Differentiable everywhere | â Stable training |
| **Probabilistic Interpretation** | Can view as preference probability | â Meaningful semantics |

#### Mathematical Example

```python
# Example calculation:
actual_rating = 0.7    # Normalized rating
predicted_rating = 0.6 # Model output

bce = -(0.7 * log(0.6) + 0.3 * log(0.4))
bce = -(0.7 * (-0.511) + 0.3 * (-0.916))
bce = -(-0.358 + (-0.275)) = 0.633
```

### B. Optimizer: Adam

```python
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)
```

#### Adam Algorithm Components

| Component | Formula | Purpose |
| --- | --- | --- |
| **Momentum** | `m_t = Î²âm_{t-1} + (1-Î²â)g_t` | Smooth gradient updates |
| **RMSprop** | `v_t = Î²âv_{t-1} + (1-Î²â)g_tÂ²` | Adaptive learning rates |
| **Bias Correction** | `mÌ_t = m_t/(1-Î²âáµ)` | Unbiased estimates |
| **Parameter Update** | `Î¸_t = Î¸_{t-1} - Î±ÃmÌ_t/âvÌ_t` | Final weight update |

#### Default Parameters

| Parameter | Default Value | Function |
| --- | --- | --- |
| **`learning_rate`** | 1e-4 | Step size for updates |
| **`beta_1`** | 0.9 | Momentum decay rate |
| **`beta_2`** | 0.999 | RMSprop decay rate |
| **`epsilon`** | 1e-7 | Numerical stability |

#### Learning Rate Selection: 1e-4

| Factor | Consideration | Rationale |
| --- | --- | --- |
| **Dataset Size** | 1M+ samples | Conservative rate for stability |
| **Model Complexity** | 22M parameters | Avoid overshooting optima |
| **Embedding Training** | Large embedding layers | Gentle updates for convergence |
| **Empirical Evidence** | Proven effective | Industry standard for CF |

### C. Metrics: RootMeanSquaredError

```python
metrics=[tf.keras.metrics.RootMeanSquaredError()]
```

#### RMSE Analysis

| Aspect | Description | Benefit |
| --- | --- | --- |
| **Formula** | `â(Î£(y-Å·)Â²/n)` | Penalizes large errors |
| **Unit** | Same as target | Interpretable results |
| **Range** | [0, â) | Lower is better |
| **Sensitivity** | High for outliers | Robust error measurement |

#### RMSE Interpretation for Ratings

```python
# Example interpretation:
rmse = 0.15  # On normalized scale [0,1]

# Convert to original scale [0,10]:
original_rmse = rmse * (10 - 0) = 1.5

# Interpretation: Average error of Â±1.5 rating points
```

***

**1. Inisialisasi Model**

```python
model = RecommenderBook(num_users, num_books, 50)
```

**Fungsi**

Membuat instance dari kelas `RecommenderBook` dengan parameter yang telah ditentukan.

**Parameter yang Digunakan**

| Parameter | Nilai | Penjelasan |
| --- | --- | --- |
| `num_users` | 105,283 | Jumlah user unik dalam dataset |
| `num_books` | 340,556 | Jumlah buku unik dalam dataset |
| `embedding_size` | 50 | Dimensi vektor embedding |

**Mengapa Embedding Size = 50?**

- **Keseimbangan**: Tidak terlalu kecil (underfitting) atau besar (overfitting)
- **Computational Efficiency**: Ukuran yang reasonable untuk training
- **Memory Usage**: Total parameters â (105,283 + 340,556) Ã 50 = ~22M parameters
- **Empirical Sweet Spot**: Umumnya 50-200 memberikan hasil optimal

Konfigurasi ini mengoptimalkan model untuk **collaborative filtering** dengan pendekatan yang **conservative** namun **effective**, menggunakan **BinaryCrossentropy** untuk training yang stabil dan **RMSE** untuk evaluasi yang interpretable.

# ð Model Training - Collaborative Filtering Training Process

## Tujuan

Melakukan **training model** collaborative filtering dengan data yang telah dipersiapkan menggunakan **supervised learning approach** untuk mempelajari pola preferensi user-book.

## Training Configuration

```python
history = model.fit(
    X_train, Y_train, 
    validation_data=(X_val, Y_val), 
    batch_size=64, 
    epochs=25
)
```

## Parameter Analysis

### 1. **Training Data**

| Parameter | Value | Shape | Content |
| --- | --- | --- | --- |
| **`X_train`** | Training features | (977,313, 2) | [user_encoded, book_encoded] |
| **`Y_train`** | Training targets | (977,313,) | Normalized ratings [0-1] |

#### Data Flow Example

```python
# Sample training batch:
X_train[0:3] = [[0, 0], [1, 1], [2, 2]]  # [user_id, book_id] pairs
Y_train[0:3] = [0.0, 0.5, 0.8]           # Corresponding normalized ratings
```

### 2. **Validation Data**

```python
validation_data=(X_val, Y_val)
```

| Parameter | Value | Shape | Purpose |
| --- | --- | --- | --- |
| **`X_val`** | Validation features | (172,467, 2) | Performance monitoring |
| **`Y_val`** | Validation targets | (172,467,) | Overfitting detection |

#### Validation Benefits

- **Performance Monitoring**: Track generalization during training
- **Early Stopping**: Detect when to stop training
- **Hyperparameter Tuning**: Compare different configurations
- **Overfitting Detection**: Monitor train-val gap

### 3. **Batch Size: 64**

```python
batch_size=64
```

#### Batch Size Analysis

| Aspect | Impact | Reasoning |
| --- | --- | --- |
| **Memory Usage** | Moderate | 64 Ã 2 Ã 4 bytes = 512 bytes per batch |
| **Gradient Stability** | Good | Sufficient samples for stable gradients |
| **Training Speed** | Balanced | Not too small (slow) or large (memory) |
| **Convergence** | Stable | Good balance of speed vs stability |

# ð Training Visualization - RMSE Performance Analysis

## Tujuan

Memvisualisasikan **performa training model** melalui grafik RMSE untuk menganalisis konvergensi, deteksi overfitting, dan evaluasi kualitas pembelajaran model.

## Code Implementation

```python
plt.plot(history.history["root_mean_squared_error"])
plt.plot(history.history["val_root_mean_squared_error"])
plt.title("RMSE metrics plot")
plt.xlabel("Epochs")
plt.ylabel("RMSE")
plt.legend(["train","test"])
plt.savefig("evaluation.png", dpi=75)
plt.show()
```

## Parameter Analysis

### 1. **Data Plotting**

| Code | Parameter | Function | Data Source |
| --- | --- | --- | --- |
| `plt.plot(history.history["root_mean_squared_error"])` | Training RMSE array | Plot training curve | Model training history |
| `plt.plot(history.history["val_root_mean_squared_error"])` | Validation RMSE array | Plot validation curve | Model validation history |

#### Data Structure

```python
# history.history structure:
{
    "root_mean_squared_error": [0.40, 0.38, 0.36, ..., 0.325],      # 25 values
    "val_root_mean_squared_error": [0.395, 0.375, 0.355, ..., 0.340] # 25 values
}
```

### 2. **Plot Configuration**

| Function | Parameter | Value | Purpose |
| --- | --- | --- | --- |
| `plt.title()` | String | "RMSE metrics plot" | Graph title |
| `plt.xlabel()` | String | "Epochs" | X-axis label |
| `plt.ylabel()` | String | "RMSE" | Y-axis label |
| `plt.legend()` | List | ["train","test"] | Line identification |

### 3. **Output Configuration**

| Function | Parameter | Value | Purpose |
| --- | --- | --- | --- |
| `plt.savefig()` | filename | "evaluation.png" | Save graph as file |
| `plt.savefig()` | dpi | 75 | Image resolution |
| `plt.show()` | None | - | Display graph |

#### DPI Selection Analysis

| DPI Value | Quality | File Size | Use Case |
| --- | --- | --- | --- |
| **75** | Standard | Small (~50KB) | Quick visualization |
| 150 | High | Medium (~200KB) | Presentation quality |
| 300 | Print | Large (~800KB) | Publication ready |

***

## Output Analysis

### Visual Interpretation

#### **Training Curve (Blue Line)**

| Epoch Range | RMSE Value | Behavior | Analysis |
| --- | --- | --- | --- |
| **0-5** | 0.40 â 0.35 | Rapid decrease | Fast initial learning |
| **5-15** | 0.35 â 0.33 | Steady decline | Consistent improvement |
| **15-25** | 0.33 â 0.325 | Gradual improvement | Fine-tuning phase |

#### **Validation Curve (Orange Line)**

| Epoch Range | RMSE Value | Behavior | Analysis |
| --- | --- | --- | --- |
| **0-5** | 0.395 â 0.355 | Quick improvement | Good generalization |
| **5-15** | 0.355 â 0.345 | Stable decline | Healthy learning |
| **15-25** | 0.345 â 0.340 | Plateau | Convergence reached |

***

## Performance Metrics Conversion

### RMSE Scale Conversion

```python
# Convert normalized RMSE to original rating scale:
final_train_rmse = 0.325  # From graph
final_val_rmse = 0.340    # From graph

# Original scale [0-10]:
original_train_rmse = final_train_rmse * 10 = 3.25
original_val_rmse = final_val_rmse * 10 = 3.40
```

### Performance Summary Table

| Metric | Initial | Final | Improvement | Original Scale |
| --- | --- | --- | --- | --- |
| **Training RMSE** | 0.40 | 0.325 | 18.75% | Â±3.25 points |
| **Validation RMSE** | 0.395 | 0.340 | 13.92% | Â±3.40 points |
| **Train-Val Gap** | 0.005 | 0.015 | +200% | Â±0.15 points |

***

**Fungsi Setiap Baris**

| Kode | Fungsi |
| --- | --- |
| `plt.plot(history.history["root_mean_squared_error"])` | Plot RMSE training |
| `plt.plot(history.history["val_root_mean_squared_error"])` | Plot RMSE validation |
| `plt.title("RMSE metrics plot")` | Judul grafik |
| `plt.xlabel("Epochs")` | Label sumbu X |
| `plt.ylabel("RMSE")` | Label sumbu Y |
| `plt.legend(["train","test"])` | Legenda biru=train, orange=test |
| `plt.savefig("evaluation.png", dpi=75)` | Simpan gambar |
| `plt.show()` | Tampilkan grafik |

***

**Analisis Output Grafik**

**A. Karakteristik Kurva Training (Biru)**

**Pola:**

- **Epoch 0-5**: Penurunan cepat dari ~0.40 ke ~0.35
- **Epoch 5-15**: Penurunan bertahap dari ~0.35 ke ~0.33
- **Epoch 15-25**: Penurunan lambat dari ~0.33 ke ~0.325

**Interpretasi:**

- **Fast Learning Phase**: Model cepat belajar pola dasar
- **Fine-tuning Phase**: Optimisasi detail
- **Convergence Phase**: Mendekati optimal point

**B. Karakteristik Kurva Validation (Orange)**

**Pola:**

- **Epoch 0-5**: Penurunan dari ~0.375 ke ~0.355
- **Epoch 5-15**: Penurunan bertahap ke ~0.345
- **Epoch 15-25**: Relatif stabil di ~0.340

**Interpretasi:**

- **Good Generalization**: Validation loss mengikuti training loss
- **No Overfitting**: Tidak ada divergence yang signifikan

***

**Evaluasi Performa Model**

**A. RMSE Values Analysis**

| Metric | Initial | Final | Improvement |
| --- | --- | --- | --- |
| **Training RMSE** | ~0.40 | ~0.325 | 18.75% |
| **Validation RMSE** | ~0.375 | ~0.340 | 9.33% |

**B. Konversi ke Skala Rating Asli**

```python
# RMSE dalam skala normalized [0,1]
final_train_rmse = 0.325
final_val_rmse = 0.340

# Konversi ke skala asli [0,10]
original_scale_train = final_train_rmse * 10 = 3.25
original_scale_val = final_val_rmse * 10 = 3.40
```

**Interpretasi**:

- Model memiliki **rata-rata error Â±3.25** pada training set
- Model memiliki **rata-rata error Â±3.40** pada validation set

***
# Hasil 



**1. Inisialisasi Data**

```python
book_df = book_new
df = pd.read_csv("/content/Ratings.csv")
```

**Fungsi**

- **`book_df`**: Alias untuk dataframe buku (berisi mapping ISBN â title)
- **`df`**: Load ulang dataset ratings asli dengan kolom nama original

**Mengapa Load Ulang?**

- Dataset asli memiliki kolom `"User-ID"` dan `"ISBN"` (dengan huruf kapital)
- Diperlukan untuk mencari user dan buku yang belum dibaca

***

**2. Pemilihan User Random**

```python
user_id = df["User-ID"].sample(1).iloc[0]
```

**Cara Kerja**

- **`.sample(1)`**: Mengambil 1 user secara random dari dataset
- **`.iloc[0]`**: Ekstrak nilai user_id dari pandas Series

**3. Identifikasi Buku yang Sudah Dibaca**

```python
readed_book_by_user = df[df["User-ID"] == user_id]
```

**Fungsi**

Mengfilter semua rating yang pernah diberikan oleh user terpilih

**Informasi yang Diperoleh**

- **Daftar buku** yang sudah pernah dibaca user
- **Rating** yang diberikan untuk setiap buku
- **Preferensi historis** user

***

**4. Identifikasi Buku yang Belum Dibaca**

```python
book_not_readed = book_df[~book_df["isbn"].isin(readed_book_by_user["ISBN"].values)]["isbn"]
```

**Cara Kerja**

**A. Ekstraksi ISBN yang Sudah Dibaca**

```python
readed_book_by_user["ISBN"].values
# Output: array(['034545104X', '0155061224', '0446520802', ...])
```

**B. Filter dengan Negasi (~)**

```python
~book_df["isbn"].isin(...)
# Mengambil buku yang TIDAK ada dalam daftar yang sudah dibaca
```

**C. Hasil**

```python
# book_not_readed berisi ISBN buku yang belum pernah dibaca user
```

***

**5. Filtering Buku yang Valid untuk Prediksi**

```python
book_not_readed = list(
    set(book_not_readed).intersection(set(isbn_encoded.keys()))
)
```

**Fungsi**

Memastikan hanya buku yang ada dalam **encoding dictionary** yang digunakan

**Cara Kerja**

- **`set(book_not_readed)`**: Convert ke set untuk operasi intersection
- **`set(isbn_encoded.keys())`**: Set semua ISBN yang ada dalam model
- **`.intersection()`**: Ambil irisan (buku yang ada di kedua set)

**Mengapa Perlu Filtering?**

- **Model Limitation**: Model hanya bisa prediksi untuk ISBN yang ada dalam training
- **Data Consistency**: Menghindari error saat encoding
- **Valid Predictions**: Memastikan semua prediksi valid

***

**6. Encoding User ID**

```python
user_encoder = user_encoded.get(user_id)
```

**Fungsi**

Mengkonversi `user_id` asli menjadi **encoded index** yang dipahami model

**Contoh**

```python
# Jika user_id = 276725
user_encoder = user_encoded.get(276725)  # Output: 0
```

***

**7. Persiapan Input Array untuk Model**

```python
book_not_readed = [[isbn_encoded.get(x)] for x in book_not_readed]
user_book_array = np.hstack(
    ([[user_encoder]] * len(book_not_readed), book_not_readed)
)
```

**A. Encoding ISBN**

```python
book_not_readed = [[isbn_encoded.get(x)] for x in book_not_readed]
```

**Fungsi**: Mengkonversi setiap ISBN menjadi encoded index dalam format list

**Contoh Transformasi**:

```python
# Before: ['034545104X', '0155061224', ...]
# After: [[0], [1], [2], ...]
```

**B. Pembuatan Input Array**

```python
user_book_array = np.hstack(
    ([[user_encoder]] * len(book_not_readed), book_not_readed)
)
```

**Cara Kerja**:

**Step 1**: Replikasi User Encoder

```python
[[user_encoder]] * len(book_not_readed)
# Jika user_encoder = 0 dan ada 1000 buku:
# [[0], [0], [0], ..., [0]]  # 1000 kali
```

**Step 2**: Horizontal Stack

```python
# Gabungkan user_id dengan setiap book_id
user_array = [[0], [0], [0], ...]     # User column
book_array = [[0], [1], [2], ...]     # Book column

# Result:
user_book_array = [[0, 0], [0, 1], [0, 2], ...]
```

***

Penjelasan Kode: Generasi Rekomendasi dan Output

**1. Prediksi Rating dengan Model**

```python
ratings = model.predict(user_book_array).flatten()
```

**Cara Kerja**

- **`model.predict()`**: Menjalankan forward pass model untuk semua kombinasi user-book
- **Input**: `user_book_array` dengan shape `(n_books, 2)` â `[user_encoded, book_encoded]`
- **`.flatten()`**: Mengkonversi output 2D menjadi 1D array

**Parameter dan Fungsi**

| Parameter | Fungsi | Shape |
| --- | --- | --- |
| `user_book_array` | Input kombinasi user-book | `(n_books, 2)` |
| Output model | Predicted ratings (normalized 0-1) | `(n_books, 1)` |
| `.flatten()` | Konversi ke 1D array | `(n_books,)` |


***

**2. Identifikasi Top 10 Rekomendasi**

```python
top_ratings_indices = ratings.argsort()[-10:][::-1]
```

**Cara Kerja Step-by-Step**

**A. `.argsort()`**

```python
ratings = [0.23, 0.89, 0.45, 0.67, 0.91, 0.12]
ratings.argsort()  # Output: [5, 0, 2, 3, 1, 4]
# Mengurutkan INDEX berdasarkan nilai (ascending)
```

**B. `[-10:]`**

```python
# Mengambil 10 index terakhir (rating tertinggi)
top_10_indices = [1, 4]  # 2 teratas dari contoh
```

**C. `[::-1]`**

```python
# Membalik urutan menjadi descending
top_ratings_indices = [4, 1]  # Rating tertinggi â terendah
```

**Hasil**

Index buku dengan 10 rating prediksi tertinggi, terurut descending

***

**3. Mapping ke ISBN Asli**

```python
recommended_book_id = [
    isbn_decoded.get(book_not_readed[x][0]) for x in top_ratings_indices
]
```

**Cara Kerja**

**A. Ekstraksi Encoded Book ID**

```python
# Untuk setiap index dalam top_ratings_indices:
x = top_ratings_indices[0]  # Index pertama
book_encoded_id = book_not_readed[x][0]  # Encoded book ID
```

**B. Decoding ke ISBN**

```python
isbn_original = isbn_decoded.get(book_encoded_id)
# Konversi encoded ID kembali ke ISBN asli
```

**Hasil**

List ISBN asli untuk 10 buku dengan prediksi rating tertinggi

***

**4. Menampilkan Preferensi User Historis**

```python
top_book_user = (
    readed_book_by_user.sort_values(
        by = 'Book-Rating',
        ascending=False
    )
    .head(5)
    .ISBN.values
)
```

**Parameter dan Fungsi**

| Parameter | Fungsi |
| --- | --- |
| `by='Book-Rating'` | Kolom untuk sorting |
| `ascending=False` | Urutan descending (rating tinggi ke rendah) |
| `.head(5)` | Ambil 5 buku teratas |
| `.ISBN.values` | Ekstrak array ISBN |

**Tujuan**

Menampilkan **konteks preferensi** user untuk memvalidasi rekomendasi

***

**5. Display Buku dengan Rating Tinggi dari User**

```python
book_df_rows = book_df[book_df['isbn'].isin(top_book_user)].drop_duplicates()
for row in book_df_rows.itertuples():
    print(row.isbn, ':', row.title)
```

**Cara Kerja**

- **`.isin(top_book_user)`**: Filter buku yang ada dalam top 5 user
- **`.drop_duplicates()`**: Hapus duplikasi jika ada
- **`.itertuples()`**: Iterator untuk setiap baris
- **`row.isbn`, `row.title`**: Akses kolom ISBN dan title

***

**6. Display Top 10 Rekomendasi**

```python
recommended_book = book_df[book_df['isbn'].isin(recommended_book_id)].drop_duplicates()
for row in recommended_book.itertuples():
    print(row.isbn, ':', row.title)
```

**Fungsi Sama dengan Section 5**

Menampilkan detail buku yang direkomendasikan model

***

**7. Analisis Output**

**A. User Profile (User 231210)**

```javascript
Book with high ratings from user:
1. The Advocate Adviser (Gay Columnist)
2. Physicians' Desk Reference 1998
3. Who's in a Family?
4. Times Family Atlas of the World
5. Real Kids, Real Adventures #1
```

**Analisis Preferensi**:

- **Diverse Interests**: Kesehatan, keluarga, petualangan
- **Non-fiction Tendency**: Referensi dan panduan
- **Family-oriented**: Buku tentang keluarga dan anak

**B. Model Recommendations**

```javascript
Top 10 Recommendations:
1. Harry Potter Series (4 buku)
2. Children's Poetry (Shel Silverstein)
3. Love You Forever
4. El Hobbit
5. A Kiss for Little Bear
```

**Analisis Rekomendasi**:

- **Genre Shift**: Model merekomendasikan fiksi anak
- **Pattern Recognition**: Menangkap preferensi family-friendly content
- **Popular Titles**: Buku-buku dengan rating tinggi secara umum

Sistem berhasil menghasilkan rekomendasi yang **relevan** dan **berkualitas**, meskipun ada **room for improvement** dalam hal personalisasi yang lebih detail. Model menunjukkan kemampuan untuk menangkap pola preferensi dan menghasilkan rekomendasi yang **meaningful** untuk user.

***
# Evaluation

Penjelasan Kode: Generasi Rekomendasi dan Output

**1. Prediksi Rating dengan Model**

```python
ratings = model.predict(user_book_array).flatten()
```

**Cara Kerja**

- **`model.predict()`**: Menjalankan forward pass model untuk semua kombinasi user-book
- **Input**: `user_book_array` dengan shape `(n_books, 2)` â `[user_encoded, book_encoded]`
- **`.flatten()`**: Mengkonversi output 2D menjadi 1D array

**Parameter dan Fungsi**

| Parameter | Fungsi | Shape |
| --- | --- | --- |
| `user_book_array` | Input kombinasi user-book | `(n_books, 2)` |
| Output model | Predicted ratings (normalized 0-1) | `(n_books, 1)` |
| `.flatten()` | Konversi ke 1D array | `(n_books,)` |


***

**2. Identifikasi Top 10 Rekomendasi**

```python
top_ratings_indices = ratings.argsort()[-10:][::-1]
```

**Cara Kerja Step-by-Step**

**A. `.argsort()`**

```python
ratings = [0.23, 0.89, 0.45, 0.67, 0.91, 0.12]
ratings.argsort()  # Output: [5, 0, 2, 3, 1, 4]
# Mengurutkan INDEX berdasarkan nilai (ascending)
```

**B. `[-10:]`**

```python
# Mengambil 10 index terakhir (rating tertinggi)
top_10_indices = [1, 4]  # 2 teratas dari contoh
```

**C. `[::-1]`**

```python
# Membalik urutan menjadi descending
top_ratings_indices = [4, 1]  # Rating tertinggi â terendah
```

**Hasil**

Index buku dengan 10 rating prediksi tertinggi, terurut descending

***

**3. Mapping ke ISBN Asli**

```python
recommended_book_id = [
    isbn_decoded.get(book_not_readed[x][0]) for x in top_ratings_indices
]
```

**Cara Kerja**

**A. Ekstraksi Encoded Book ID**

```python
# Untuk setiap index dalam top_ratings_indices:
x = top_ratings_indices[0]  # Index pertama
book_encoded_id = book_not_readed[x][0]  # Encoded book ID
```

**B. Decoding ke ISBN**

```python
isbn_original = isbn_decoded.get(book_encoded_id)
# Konversi encoded ID kembali ke ISBN asli
```

**Hasil**

List ISBN asli untuk 10 buku dengan prediksi rating tertinggi

***

**4. Menampilkan Preferensi User Historis**

```python
top_book_user = (
    readed_book_by_user.sort_values(
        by = 'Book-Rating',
        ascending=False
    )
    .head(5)
    .ISBN.values
)
```

**Parameter dan Fungsi**

| Parameter | Fungsi |
| --- | --- |
| `by='Book-Rating'` | Kolom untuk sorting |
| `ascending=False` | Urutan descending (rating tinggi ke rendah) |
| `.head(5)` | Ambil 5 buku teratas |
| `.ISBN.values` | Ekstrak array ISBN |

**Tujuan**

Menampilkan **konteks preferensi** user untuk memvalidasi rekomendasi

***

**5. Display Buku dengan Rating Tinggi dari User**

```python
book_df_rows = book_df[book_df['isbn'].isin(top_book_user)].drop_duplicates()
for row in book_df_rows.itertuples():
    print(row.isbn, ':', row.title)
```

**Cara Kerja**

- **`.isin(top_book_user)`**: Filter buku yang ada dalam top 5 user
- **`.drop_duplicates()`**: Hapus duplikasi jika ada
- **`.itertuples()`**: Iterator untuk setiap baris
- **`row.isbn`, `row.title`**: Akses kolom ISBN dan title

***

**6. Display Top 10 Rekomendasi**

```python
recommended_book = book_df[book_df['isbn'].isin(recommended_book_id)].drop_duplicates()
for row in recommended_book.itertuples():
    print(row.isbn, ':', row.title)
```

**Fungsi Sama dengan Section 5**

Menampilkan detail buku yang direkomendasikan model

***

**7. Analisis Output**

**A. User Profile (User 231210)**

```javascript
Book with high ratings from user:
1. The Advocate Adviser (Gay Columnist)
2. Physicians' Desk Reference 1998
3. Who's in a Family?
4. Times Family Atlas of the World
5. Real Kids, Real Adventures #1
```

**Analisis Preferensi**:

- **Diverse Interests**: Kesehatan, keluarga, petualangan
- **Non-fiction Tendency**: Referensi dan panduan
- **Family-oriented**: Buku tentang keluarga dan anak

**B. Model Recommendations**

```javascript
Top 10 Recommendations:
1. Harry Potter Series (4 buku)
2. Children's Poetry (Shel Silverstein)
3. Love You Forever
4. El Hobbit
5. A Kiss for Little Bear
```

**Analisis Rekomendasi**:

- **Genre Shift**: Model merekomendasikan fiksi anak
- **Pattern Recognition**: Menangkap preferensi family-friendly content
- **Popular Titles**: Buku-buku dengan rating tinggi secara umum

Sistem berhasil menghasilkan rekomendasi yang **relevan** dan **berkualitas**, meskipun ada **room for improvement** dalam hal personalisasi yang lebih detail. Model menunjukkan kemampuan untuk menangkap pola preferensi dan menghasilkan rekomendasi yang **meaningful** untuk user.

# Penjelasan Evaluasi Model Collaborative Filtering

## 1. Fungsi dan Tujuan Evaluasi

### **Tujuan Utama Evaluasi:**

Evaluasi model bertujuan untuk mengukur seberapa baik sistem rekomendasi Collaborative Filtering dapat **menjawab problem statement** yang telah dirumuskan:

1. **Mempercepat proses pencarian buku**: Dengan mengukur akurasi prediksi rating, kita dapat memastikan sistem memberikan rekomendasi yang relevan, sehingga pengguna tidak perlu menghabiskan waktu mencari buku secara manual.

2. **Mengembangkan sistem rekomendasi yang akurat**: Evaluasi memvalidasi kemampuan model dalam memprediksi preferensi pengguna berdasarkan data rating historis.

### **Fungsi Evaluasi:**

- **Validasi Performa**: Memastikan model dapat memprediksi rating dengan akurat
- **Deteksi Overfitting**: Mengidentifikasi apakah model terlalu spesifik pada data training
- **Interpretasi Bisnis**: Menerjemahkan metrik teknis ke dalam konteks bisnis yang dapat dipahami
- **Optimasi Model**: Memberikan insight untuk perbaikan model di masa depan

***

## 2. Cara Kerja Sistem Evaluasi

### **Alur Kerja Evaluasi:**

```javascript
Data Test (X_val, Y_val) â Prediksi Model â Denormalisasi â Perhitungan Metrik â Interpretasi
```

### **Proses Detail:**

1. **Persiapan Data Test**:

- Menggunakan validation set sebagai data test
- Data berisi pasangan (user_encoded, isbn_encoded) dan rating yang dinormalisasi

2. **Prediksi Model**:

- Model memprediksi rating untuk pasangan user-book pada data test
- Output berupa nilai probabilitas (0-1) karena menggunakan sigmoid activation

3. **Denormalisasi**:

- Mengkonversi hasil prediksi dari skala 0-1 kembali ke skala asli 0-10
- Formula: `rating_asli = normalized_rating Ã (max - min) + min`

4. **Perhitungan Metrik**:

- Menghitung berbagai metrik evaluasi pada skala asli dan normalized
- Membandingkan prediksi dengan rating aktual

5. **Analisis dan Interpretasi**:

- Mengkategorikan performa model
- Memberikan rekomendasi perbaikan

***

## 3. Parameter dan Metrik yang Digunakan

### **A. Parameter Normalisasi:**

| Parameter | Nilai | Fungsi |
| --- | --- | --- |
| `min` | Rating minimum (0) | Batas bawah normalisasi |
| `max` | Rating maximum (10) | Batas atas normalisasi |
| **Formula** | `(x - min) / (max - min)` | Mengkonversi rating ke skala 0-1 |

**Fungsi Normalisasi:**

- Menstandardisasi input untuk model neural network
- Membantu konvergensi training yang lebih stabil
- Memungkinkan penggunaan sigmoid activation function

### **B. Metrik Evaluasi Utama:**

#### **1. Root Mean Squared Error (RMSE)**

```python
rmse = â(Î£(y_true - y_pred)Â²/n)
```

- **Fungsi**: Mengukur rata-rata kesalahan prediksi dengan memberikan penalti lebih besar pada error yang besar
- **Interpretasi**: Semakin rendah semakin baik
- **Skala**: Sama dengan skala rating asli (0-10)
- **Keunggulan**: Sensitif terhadap outlier, cocok untuk deteksi prediksi yang sangat meleset

#### **2. Mean Absolute Error (MAE)**

```python
mae = Î£|y_true - y_pred|/n
```

- **Fungsi**: Mengukur rata-rata absolut kesalahan prediksi
- **Interpretasi**: Rata-rata seberapa jauh prediksi dari nilai sebenarnya
- **Keunggulan**: Lebih robust terhadap outlier dibanding RMSE
- **Konteks Bisnis**: Menunjukkan rata-rata kesalahan prediksi rating dalam poin

#### **3. RÂ² Score (Coefficient of Determination)**

```python
r2 = 1 - (SS_res / SS_tot)
```

- **Fungsi**: Mengukur seberapa baik model menjelaskan variabilitas data
- **Range**: -â hingga 1 (1 = perfect fit)
- **Interpretasi**:
- 0.9-1.0: Excellent
- 0.8-0.9: Very Good
- 0.7-0.8: Good
- <0.7: Perlu perbaikan

#### **4. Mean Absolute Percentage Error (MAPE)**

```python
mape = (100/n) Ã Î£|((y_true - y_pred)/y_true)|
```

- **Fungsi**: Mengukur kesalahan dalam bentuk persentase
- **Keunggulan**: Scale-independent, mudah diinterpretasi bisnis
- **Interpretasi**: Persentase rata-rata kesalahan prediksi

### **C. Metrik Akurasi Toleransi:**

#### **Akurasi Â±1 Poin**

```python
accuracy_1 = (jumlah_prediksi_dalam_toleransi_1_poin / total_prediksi) Ã 100%
```

- **Fungsi**: Mengukur persentase prediksi yang akurat dalam toleransi Â±1 poin rating
- **Konteks Bisnis**: Menunjukkan seberapa sering sistem memberikan rekomendasi yang "hampir tepat"

#### **Akurasi Â±2 Poin**

```python
accuracy_2 = (jumlah_prediksi_dalam_toleransi_2_poin / total_prediksi) Ã 100%
```

- **Fungsi**: Mengukur persentase prediksi yang dapat diterima dalam toleransi Â±2 poin
- **Konteks Bisnis**: Standar minimum untuk rekomendasi yang "cukup baik"

***

## 4. Analisis Kategori Rating

### **Kategorisasi Rating:**

- **Low (0-3)**: Buku yang tidak disukai
- **Medium (4-6)**: Buku dengan rating sedang
- **High (7-10)**: Buku yang sangat disukai

### **Fungsi Analisis Kategori:**

1. **Identifikasi Bias Model**: Apakah model lebih baik memprediksi kategori tertentu
2. **Strategi Rekomendasi**: Fokus pada kategori High untuk rekomendasi terbaik
3. **Validasi Bisnis**: Memastikan model dapat membedakan preferensi pengguna

***

## 5. Menjawab Problem Statement

### **Problem 1: Mempercepat Proses Pencarian Buku**

**Solusi melalui Evaluasi:**

- **Metrik Akurasi Toleransi**: Memastikan â¥80% prediksi dalam toleransi Â±2 poin
- **RMSE â¤ 2.0**: Menjamin prediksi yang cukup akurat untuk rekomendasi
- **Analisis Kategori High**: Fokus pada buku dengan rating tinggi untuk rekomendasi prioritas

**Cara Kerja:**

1. Sistem memprediksi rating untuk buku yang belum dibaca pengguna
2. Mengurutkan buku berdasarkan prediksi rating tertinggi
3. Memberikan top-10 rekomendasi yang paling relevan
4. **Hasil**: Pengguna tidak perlu browsing manual, langsung mendapat rekomendasi personal

### **Problem 2: Sistem Rekomendasi Berdasarkan Data Penilaian**

**Solusi melalui Evaluasi:**

- **RÂ² Score â¥ 0.7**: Memastikan model dapat menangkap pola preferensi pengguna
- **MAE â¤ 1.5**: Menjamin prediksi rating yang akurat
- **Confusion Matrix**: Validasi kemampuan model membedakan preferensi

**Cara Kerja:**

1. **Collaborative Filtering**: Menganalisis pola rating pengguna serupa
2. **Matrix Factorization**: Mengidentifikasi faktor laten yang mempengaruhi preferensi
3. **Embedding Learning**: Mempelajari representasi user dan book dalam ruang laten
4. **Prediksi Rating**: Menghitung kemungkinan rating untuk buku yang belum dibaca

***

## 6. Interpretasi Hasil Evaluasi

### **Standar Performa yang Baik:**

| Metrik | Excellent | Good | Fair | Poor |
| --- | --- | --- | --- | --- |
| RMSE | â¤ 1.5 | â¤ 2.0 | â¤ 2.5 | > 2.5 |
| RÂ² | â¥ 0.9 | â¥ 0.7 | â¥ 0.5 | < 0.5 |
| Akurasi Â±2 | â¥ 90% | â¥ 80% | â¥ 70% | < 70% |

### **Konteks Bisnis:**

- **RMSE 1.5**: Rata-rata kesalahan prediksi 1.5 poin dari rating sebenarnya
- **Akurasi 80%**: 8 dari 10 rekomendasi memiliki rating yang cukup akurat
- **RÂ² 0.7**: Model dapat menjelaskan 70% variasi preferensi pengguna

### **Dampak pada Problem Statement:**

1. **Efisiensi Pencarian**: Model dengan performa baik dapat mengurangi waktu pencarian dari jam menjadi detik
2. **Akurasi Rekomendasi**: Sistem dapat memprediksi preferensi dengan tingkat kepercayaan tinggi
3. **Personalisasi**: Setiap pengguna mendapat rekomendasi yang disesuaikan dengan riwayat rating mereka

***

## 7. Kesimpulan Evaluasi

### **Validasi Solusi:**

Sistem evaluasi memvalidasi bahwa model Collaborative Filtering dapat:

1. â **Mempercepat pencarian**: Memberikan rekomendasi instan berdasarkan preferensi
2. â **Memanfaatkan data rating**: Menggunakan pola rating historis untuk prediksi
3. â **Personalisasi**: Memberikan rekomendasi yang disesuaikan per pengguna
4. â **Akurasi tinggi**: Prediksi rating dengan tingkat kesalahan yang dapat diterima

### **Kontribusi terhadap Problem Statement:**

- **Efisiensi**: Mengurangi waktu pencarian buku dari manual browsing menjadi rekomendasi otomatis
- **Akurasi**: Memastikan rekomendasi sesuai dengan preferensi pengguna berdasarkan data historis
- **Skalabilitas**: Sistem dapat menangani jutaan interaksi user-book untuk memberikan rekomendasi real-time

# Penjelasan Output Evaluasi Model Collaborative Filtering

## 1. Analisis Output Evaluasi

### **A. Persiapan Data Test**

```javascript
â Data test disiapkan dari validation set
   â¢ Jumlah sampel test: 172,467
   â¢ Range rating (normalized): 0.0000 - 1.0000
```

**Penjelasan Output:**

- **172,467 sampel**: Dataset test yang cukup besar untuk evaluasi yang robust
- **Range 0-1**: Konfirmasi bahwa normalisasi berhasil mengkonversi rating ke skala 0-1
- **Normalisasi formula**: `(x - 0) / (10 - 0) = x/10` - sederhana karena rating asli sudah 0-10

### **B. Hasil Prediksi Model**

```javascript
â Prediksi selesai!
   â¢ Range prediksi (normalized): 0.0000 - 0.8562
   â¢ Mean prediksi (normalized): 0.1548
```

**Analisis Kritis:**

- **Range prediksi hanya 0-0.86**: Model tidak pernah memprediksi rating maksimal (setara 8.6/10)
- **Mean prediksi 0.15**: Model cenderung memprediksi rating rendah (setara 1.5/10)
- **â ï¸ Problem**: Model mengalami **underprediction bias** - selalu memprediksi lebih rendah

### **C. Denormalisasi ke Skala Asli**

```javascript
â Denormalisasi selesai!
   â¢ Mean rating asli: 2.87
   â¢ Mean prediksi asli: 1.55
```

**Interpretasi:**

- **Gap signifikan**: Selisih 1.32 poin antara rata-rata actual vs predicted
- **Bias sistematis**: Model konsisten memprediksi lebih rendah dari kenyataan
- **Implikasi bisnis**: Sistem akan meremehkan preferensi pengguna

***

## 2. Analisis Metrik Evaluasi

### **A. Metrik Utama - Performa Buruk**

```javascript
RMSE (Skala 0-10): 3.7085 (Poor)
MAE (Skala 0-10): 2.7243
RÂ² Score: 0.0735 (Poor)
```

**Penjelasan Detail:**

#### **RMSE = 3.71**

- **Interpretasi**: Rata-rata kesalahan prediksi 3.71 poin dari rating sebenarnya
- **Konteks**: Pada skala 0-10, ini adalah kesalahan 37% - sangat tinggi
- **Standar industri**: RMSE yang baik untuk sistem rekomendasi biasanya <2.0
- **â ï¸ Masalah**: Model tidak reliable untuk prediksi rating

#### **MAE = 2.72**

- **Interpretasi**: Rata-rata absolut kesalahan 2.72 poin
- **Konteks bisnis**: Jika user sebenarnya rating 8, model prediksi ~5.3
- **Dampak**: Rekomendasi tidak akurat, user mungkin tidak puas

#### **RÂ² = 0.0735**

- **Interpretasi**: Model hanya menjelaskan 7.35% variasi rating
- **Artinya**: 92.65% variasi tidak dapat dijelaskan model
- **â ï¸ Masalah kritis**: Model hampir tidak berguna untuk prediksi

### **B. MAPE Anomali**

```javascript
MAPE: 6987152963.16%
```

**Penjelasan Anomali:**

- **Penyebab**: Division by zero atau nilai rating actual = 0
- **Formula MAPE**: `|actual - predicted| / actual Ã 100%`
- **Masalah**: Ketika actual = 0, pembagian menghasilkan infinity
- **Solusi**: MAPE tidak cocok untuk data dengan nilai 0

### **C. Akurasi Toleransi**

```javascript
Akurasi dalam toleransi Â±1 poin: 33.81%
Akurasi dalam toleransi Â±2 poin: 54.04%
```

**Interpretasi:**

- **33.81% dalam Â±1**: Hanya 1 dari 3 prediksi yang "hampir benar"
- **54.04% dalam Â±2**: Hanya setengah prediksi yang "cukup dapat diterima"
- **Standar industri**: Minimal 80% untuk Â±2 poin
- **â ï¸ Kesimpulan**: Akurasi tidak memadai untuk sistem produksi

***

## 3. Analisis Distribusi dan Visualisasi

### **A. Statistik Deskriptif**

```javascript
       Actual  Predicted
Mean   2.8666     1.5477
Std    3.8528     1.2013
Min    0.0000     0.0003
Max   10.0000     8.5624
```

**Analisis Mendalam:**

#### **Perbedaan Mean (2.87 vs 1.55)**

- **Gap**: 1.32 poin - bias sistematis yang signifikan
- **Penyebab**: Model terlalu konservatif dalam prediksi
- **Dampak**: Sistem akan meremehkan preferensi user

#### **Perbedaan Standard Deviation (3.85 vs 1.20)**

- **Actual**: Variasi tinggi (0-10) - data natural
- **Predicted**: Variasi rendah (0-1.2) - model tidak confident
- **â ï¸ Problem**: Model tidak dapat menangkap diversitas preferensi

#### **Range Prediction (0-8.56)**

- **Missing high ratings**: Model tidak pernah prediksi >8.6
- **Implikasi**: Buku bagus tidak akan direkomendasikan dengan confidence tinggi

### **B. Analisis Visualisasi**

#### **Distribution Plot:**

- **Actual**: Distribusi U-shaped (banyak rating 0 dan tinggi)
- **Predicted**: Distribusi exponential decay (dominasi rating rendah)
- **â ï¸ Masalah**: Model tidak memahami pola preferensi user yang sebenarnya

#### **Box Plot:**

- **Actual**: Median ~7, quartile range luas
- **Predicted**: Median ~1, range sangat sempit
- **Interpretasi**: Model terlalu bias ke rating rendah

***

## 4. Analisis Per Kategori Rating

### **A. Performance Per Kategori**

```javascript
Low (0-3):   MAE: 1.12, RMSE: 1.44  â Baik
Medium (4-6): MAE: 3.25, RMSE: 3.44  â ï¸ Sedang  
High (7-10):  MAE: 6.14, RMSE: 6.35  â Buruk
```

**Insight Penting:**

- **Model baik untuk rating rendah**: Error hanya 1.12 poin
- **Model buruk untuk rating tinggi**: Error 6.14 poin
- **Pola**: Semakin tinggi rating actual, semakin buruk prediksi
- **â ï¸ Implikasi**: Sistem tidak dapat mengidentifikasi buku berkualitas tinggi

### **B. Confusion Matrix Analysis**

```javascript
              precision    recall  f1-score   support
Low (0-3)       0.67      0.97      0.79    108977
Medium (4-6)    0.14      0.13      0.13     14567  
High (7-10)     0.91      0.03      0.06     48923
```

**Analisis Detail:**

#### **Low Category (0-3):**

- **Recall 97%**: Model sangat baik mendeteksi rating rendah
- **Precision 67%**: 2/3 prediksi "low" benar
- **Interpretasi**: Model bias memprediksi semua sebagai "low"

#### **High Category (7-10):**

- **Recall 3%**: Model hampir tidak pernah deteksi rating tinggi
- **Precision 91%**: Jika prediksi "high", biasanya benar
- **â ï¸ Problem kritis**: Model gagal mengidentifikasi preferensi tinggi

#### **Overall Accuracy: 63%**

- **Interpretation**: 6 dari 10 kategori prediksi benar
- **Bias**: Akurasi tinggi karena dominasi prediksi "low"

***

## 5. Analisis Training Performance

### **A. Overfitting Detection**

```javascript
Training RMSE: 0.3230
Validation RMSE: 0.3379
Selisih: 0.0150
â ï¸ Model mengalami sedikit overfitting
```

**Interpretasi:**

- **Gap kecil**: 0.015 - overfitting minimal
- **Bukan masalah utama**: Performa buruk bukan karena overfitting
- **Root cause**: Model capacity atau architecture yang tidak optimal

***

## 6. Diagnosis Masalah dan Solusi

### **A. Identifikasi Masalah Utama**

#### **1. Underprediction Bias**

- **Gejala**: Mean predicted (1.55) << Mean actual (2.87)
- **Penyebab**: Sigmoid activation + loss function combination
- **Dampak**: Sistem meremehkan semua preferensi

#### **2. Limited Prediction Range**

- **Gejala**: Max prediction hanya 8.56/10
- **Penyebab**: Model tidak confident untuk prediksi tinggi
- **Dampak**: Buku berkualitas tidak direkomendasikan optimal

#### **3. Poor High-Rating Detection**

- **Gejala**: Recall 3% untuk kategori High
- **Penyebab**: Model tidak belajar pattern untuk rating tinggi
- **Dampak**: Gagal mengidentifikasi buku yang benar-benar disukai

### **B. Rekomendasi Perbaikan**

#### **1. Architecture Improvements**

```python
# Tambahkan layer dan regularization
model = Sequential([
    Embedding(...),
    Dropout(0.3),
    Dense(128, activation='relu'),
    Dense(64, activation='relu'),
    Dense(1, activation='linear')  # Ganti sigmoid dengan linear
])
```

#### **2. Loss Function Optimization**

```python
# Ganti dari BinaryCrossentropy ke MSE
model.compile(
    loss='mse',  # Lebih cocok untuk regression
    optimizer=Adam(learning_rate=1e-3),
    metrics=['mae', 'rmse']
)
```

#### **3. Data Balancing**

```python
# Balance dataset per kategori rating
from sklearn.utils.class_weight import compute_class_weight
class_weights = compute_class_weight('balanced', ...)
```

***

## 7. Menjawab Problem Statement (Revisi)

### **Problem 1: Mempercepat Proses Pencarian Buku**

**Status Saat Ini: â BELUM TERCAPAI**

**Analisis:**

- **Akurasi rendah (54% dalam Â±2)**: Rekomendasi tidak reliable
- **Bias ke rating rendah**: Sistem tidak akan merekomendasikan buku bagus
- **Dampak**: User masih perlu manual search karena rekomendasi tidak akurat

**Solusi yang Diperlukan:**

- Tingkatkan akurasi minimal 80% dalam toleransi Â±2
- Perbaiki bias underprediction
- Optimasi untuk deteksi rating tinggi

### **Problem 2: Sistem Rekomendasi Berdasarkan Data Penilaian**

**Status Saat Ini: â BELUM OPTIMAL**

**Analisis:**

- **RÂ² = 7.35%**: Model tidak menangkap pola preferensi
- **Poor high-rating detection**: Gagal identify buku berkualitas
- **Systematic bias**: Tidak memanfaatkan data rating secara optimal

**Solusi yang Diperlukan:**

- Redesign architecture untuk better pattern learning
- Implement hybrid approach (content + collaborative)
- Advanced feature engineering

***

## 8. Kesimpulan dan Rekomendasi

### **A. Status Evaluasi**

```javascript
ð¨ MODEL PERLU PERBAIKAN SIGNIFIKAN
â RMSE: 3.71 (Target: <2.0)
â RÂ²: 7.35% (Target: >70%)
â Akurasi Â±2: 54% (Target: >80%)
```

### **B. Prioritas Perbaikan**

1. **Fix underprediction bias** - Ganti activation function
2. **Improve architecture** - Tambah complexity dan regularization  
3. **Balance training data** - Handle class imbalance
4. **Optimize hyperparameters** - Learning rate, embedding size, epochs

### **C. Expected Improvements**

Dengan perbaikan yang tepat, target performance:

- **RMSE**: 3.71 â <2.0 (improvement 46%)
- **RÂ²**: 7.35% â >70% (improvement 850%)
- **Akurasi Â±2**: 54% â >80% (improvement 48%)

### **D. Business Impact**

Setelah perbaikan, sistem akan dapat:

- â Memberikan rekomendasi akurat dan personal
- â Mengidentifikasi buku berkualitas tinggi
- â Mempercepat discovery proses untuk user
- â Meningkatkan user satisfaction dan engagement

**Status Final: Model memerlukan iterasi pengembangan sebelum deployment produksi.**
